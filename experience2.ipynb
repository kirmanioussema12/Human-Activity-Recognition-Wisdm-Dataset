{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1a78cfa",
   "metadata": {},
   "source": [
    "So in This Experience I've Applied Data augmentation on the class of  upstairs and downstaires with the class weightning technique on the  Sitting and standing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdeeba59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization, Add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: simple jittering function for augmentation\n",
    "def add_jitter(X, sigma=0.01):\n",
    "    noise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n",
    "    return X + noise\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\HAR-WISDM\\Data_WISDM\\WISDM_cleaned.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Encode class labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for CNN-LSTM: assuming 30 features = (10 time steps × 3 features)\n",
    "X_reshaped = X_scaled.reshape(-1, 10, 3)\n",
    "y_reshaped = y_encoded.reshape(-1)\n",
    "\n",
    "# === Data Augmentation on Downstairs and Upstairs ===\n",
    "def augment_minority_classes(X, y, classes_to_augment, augment_func, augment_factor=2):\n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    \n",
    "    for cls in classes_to_augment:\n",
    "        X_cls = X[y == cls]\n",
    "        for _ in range(augment_factor):\n",
    "            X_augmented.append(augment_func(X_cls))\n",
    "            y_augmented.append(np.full(len(X_cls), cls))\n",
    "    \n",
    "    X_aug = np.concatenate(X_augmented, axis=0)\n",
    "    y_aug = np.concatenate(y_augmented, axis=0)\n",
    "    \n",
    "    # Append augmented data to original\n",
    "    X_new = np.concatenate([X, X_aug], axis=0)\n",
    "    y_new = np.concatenate([y, y_aug], axis=0)\n",
    "    \n",
    "    return X_new, y_new\n",
    "\n",
    "# Identify classes to augment by label index\n",
    "classes_to_augment = []\n",
    "for class_name in ['Downstairs', 'Upstairs']:\n",
    "    cls_idx = label_encoder.transform([class_name])[0]\n",
    "    classes_to_augment.append(cls_idx)\n",
    "\n",
    "# Apply augmentation with jittering (augment_factor can be changed)\n",
    "X_augmented, y_augmented = augment_minority_classes(X_reshaped, y_reshaped, classes_to_augment, add_jitter, augment_factor=3)\n",
    "\n",
    "# Compute class weights on augmented data\n",
    "class_weights_aug = compute_class_weight('balanced', classes=np.unique(y_augmented), y=y_augmented)\n",
    "class_weight_dict_aug = dict(enumerate(class_weights_aug))\n",
    "\n",
    "# Visualize augmented class distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x=label_encoder.inverse_transform(y_augmented))\n",
    "plt.title('Augmented Class Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Now use X_augmented, y_augmented and class_weight_dict_aug for your training pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a7db581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Training Fold 1\n",
      "Epoch 1/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.2783 - loss: 5.2272 - val_accuracy: 0.2820 - val_loss: 3.1252 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.3801 - loss: 2.4978 - val_accuracy: 0.3629 - val_loss: 2.1260 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4190 - loss: 1.7274 - val_accuracy: 0.4242 - val_loss: 1.7051 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4276 - loss: 1.4675 - val_accuracy: 0.4635 - val_loss: 1.5248 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4258 - loss: 1.3434 - val_accuracy: 0.4573 - val_loss: 1.4123 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4232 - loss: 1.2757 - val_accuracy: 0.4708 - val_loss: 1.4050 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4469 - loss: 1.2598 - val_accuracy: 0.4831 - val_loss: 1.3420 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4483 - loss: 1.2763 - val_accuracy: 0.4556 - val_loss: 1.3552 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4516 - loss: 1.1985 - val_accuracy: 0.4725 - val_loss: 1.3398 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4573 - loss: 1.2159 - val_accuracy: 0.4545 - val_loss: 1.3729 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4605 - loss: 1.2178 - val_accuracy: 0.4961 - val_loss: 1.3068 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4699 - loss: 1.1847 - val_accuracy: 0.4882 - val_loss: 1.3072 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4654 - loss: 1.1419 - val_accuracy: 0.4904 - val_loss: 1.2994 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4806 - loss: 1.1090 - val_accuracy: 0.4983 - val_loss: 1.3039 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4825 - loss: 1.1402 - val_accuracy: 0.4961 - val_loss: 1.3174 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4887 - loss: 1.1399 - val_accuracy: 0.4697 - val_loss: 1.3309 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4945 - loss: 1.1124 - val_accuracy: 0.5045 - val_loss: 1.2540 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5046 - loss: 1.0277 - val_accuracy: 0.5213 - val_loss: 1.2315 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5083 - loss: 0.9922 - val_accuracy: 0.4994 - val_loss: 1.2372 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5142 - loss: 1.0105 - val_accuracy: 0.5315 - val_loss: 1.2142 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5146 - loss: 0.9842 - val_accuracy: 0.5000 - val_loss: 1.2810 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5137 - loss: 1.0060 - val_accuracy: 0.5270 - val_loss: 1.2179 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5225 - loss: 1.0001 - val_accuracy: 0.5326 - val_loss: 1.2143 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5366 - loss: 0.9818 - val_accuracy: 0.5573 - val_loss: 1.1714 - learning_rate: 2.5000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5423 - loss: 0.9596 - val_accuracy: 0.5556 - val_loss: 1.1374 - learning_rate: 2.5000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5656 - loss: 0.9098 - val_accuracy: 0.5556 - val_loss: 1.1327 - learning_rate: 2.5000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5523 - loss: 0.8812 - val_accuracy: 0.5590 - val_loss: 1.1231 - learning_rate: 2.5000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5745 - loss: 0.8553 - val_accuracy: 0.5680 - val_loss: 1.1180 - learning_rate: 2.5000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5741 - loss: 0.8627 - val_accuracy: 0.5758 - val_loss: 1.0955 - learning_rate: 2.5000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5852 - loss: 0.8484 - val_accuracy: 0.5612 - val_loss: 1.1182 - learning_rate: 2.5000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5992 - loss: 0.8406 - val_accuracy: 0.6096 - val_loss: 1.0708 - learning_rate: 2.5000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6036 - loss: 0.8054 - val_accuracy: 0.5921 - val_loss: 1.0914 - learning_rate: 2.5000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5969 - loss: 0.8360 - val_accuracy: 0.6096 - val_loss: 1.0742 - learning_rate: 2.5000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5984 - loss: 0.8237 - val_accuracy: 0.6191 - val_loss: 1.0660 - learning_rate: 2.5000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6089 - loss: 0.8097 - val_accuracy: 0.6253 - val_loss: 1.0601 - learning_rate: 2.5000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6209 - loss: 0.8092 - val_accuracy: 0.6135 - val_loss: 1.0488 - learning_rate: 2.5000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6132 - loss: 0.8088 - val_accuracy: 0.6287 - val_loss: 1.0507 - learning_rate: 2.5000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6211 - loss: 0.8132 - val_accuracy: 0.6365 - val_loss: 1.0462 - learning_rate: 2.5000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6391 - loss: 0.7843 - val_accuracy: 0.6287 - val_loss: 1.0619 - learning_rate: 2.5000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6496 - loss: 0.7644 - val_accuracy: 0.6506 - val_loss: 1.0230 - learning_rate: 2.5000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6592 - loss: 0.7613 - val_accuracy: 0.6494 - val_loss: 1.0189 - learning_rate: 2.5000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6581 - loss: 0.7468 - val_accuracy: 0.6472 - val_loss: 1.0101 - learning_rate: 2.5000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6728 - loss: 0.7562 - val_accuracy: 0.6545 - val_loss: 1.0251 - learning_rate: 2.5000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6680 - loss: 0.7408 - val_accuracy: 0.6590 - val_loss: 0.9867 - learning_rate: 2.5000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6833 - loss: 0.7297 - val_accuracy: 0.6719 - val_loss: 0.9805 - learning_rate: 2.5000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6819 - loss: 0.7441 - val_accuracy: 0.6949 - val_loss: 0.9594 - learning_rate: 2.5000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6794 - loss: 0.7436 - val_accuracy: 0.6860 - val_loss: 0.9632 - learning_rate: 2.5000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6926 - loss: 0.7272 - val_accuracy: 0.6764 - val_loss: 0.9827 - learning_rate: 2.5000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7021 - loss: 0.7294 - val_accuracy: 0.6910 - val_loss: 0.9733 - learning_rate: 2.5000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7154 - loss: 0.7027 - val_accuracy: 0.7011 - val_loss: 0.9395 - learning_rate: 1.2500e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7183 - loss: 0.6832 - val_accuracy: 0.7275 - val_loss: 0.8960 - learning_rate: 1.2500e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7360 - loss: 0.6582 - val_accuracy: 0.7371 - val_loss: 0.8884 - learning_rate: 1.2500e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7390 - loss: 0.6488 - val_accuracy: 0.7489 - val_loss: 0.8831 - learning_rate: 1.2500e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7522 - loss: 0.6481 - val_accuracy: 0.7640 - val_loss: 0.8579 - learning_rate: 1.2500e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7329 - loss: 0.6570 - val_accuracy: 0.7494 - val_loss: 0.8598 - learning_rate: 1.2500e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7509 - loss: 0.6414 - val_accuracy: 0.7399 - val_loss: 0.8726 - learning_rate: 1.2500e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7501 - loss: 0.6363 - val_accuracy: 0.7382 - val_loss: 0.8722 - learning_rate: 1.2500e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7719 - loss: 0.6043 - val_accuracy: 0.7860 - val_loss: 0.8064 - learning_rate: 6.2500e-05\n",
      "Epoch 59/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7769 - loss: 0.5837 - val_accuracy: 0.8034 - val_loss: 0.7895 - learning_rate: 6.2500e-05\n",
      "Epoch 60/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7728 - loss: 0.5847 - val_accuracy: 0.8017 - val_loss: 0.7824 - learning_rate: 6.2500e-05\n",
      "Epoch 61/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7917 - loss: 0.5641 - val_accuracy: 0.8051 - val_loss: 0.7792 - learning_rate: 6.2500e-05\n",
      "Epoch 62/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7992 - loss: 0.5573 - val_accuracy: 0.7966 - val_loss: 0.7835 - learning_rate: 6.2500e-05\n",
      "Epoch 63/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8059 - loss: 0.5513 - val_accuracy: 0.7978 - val_loss: 0.7783 - learning_rate: 6.2500e-05\n",
      "Epoch 64/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7914 - loss: 0.5667 - val_accuracy: 0.8264 - val_loss: 0.7373 - learning_rate: 6.2500e-05\n",
      "Epoch 65/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8015 - loss: 0.5497 - val_accuracy: 0.8067 - val_loss: 0.7615 - learning_rate: 6.2500e-05\n",
      "Epoch 66/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7873 - loss: 0.5681 - val_accuracy: 0.8242 - val_loss: 0.7350 - learning_rate: 6.2500e-05\n",
      "Epoch 67/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8094 - loss: 0.5391 - val_accuracy: 0.8208 - val_loss: 0.7357 - learning_rate: 6.2500e-05\n",
      "Epoch 68/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8076 - loss: 0.5447 - val_accuracy: 0.8213 - val_loss: 0.7210 - learning_rate: 6.2500e-05\n",
      "Epoch 69/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8006 - loss: 0.5391 - val_accuracy: 0.8213 - val_loss: 0.7264 - learning_rate: 6.2500e-05\n",
      "Epoch 70/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8002 - loss: 0.5414 - val_accuracy: 0.8225 - val_loss: 0.7155 - learning_rate: 6.2500e-05\n",
      "Epoch 71/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8079 - loss: 0.5271 - val_accuracy: 0.8326 - val_loss: 0.6967 - learning_rate: 6.2500e-05\n",
      "Epoch 72/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8060 - loss: 0.5238 - val_accuracy: 0.8354 - val_loss: 0.7063 - learning_rate: 6.2500e-05\n",
      "Epoch 73/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8242 - loss: 0.5232 - val_accuracy: 0.8393 - val_loss: 0.7017 - learning_rate: 6.2500e-05\n",
      "Epoch 74/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8045 - loss: 0.5327 - val_accuracy: 0.8376 - val_loss: 0.6915 - learning_rate: 6.2500e-05\n",
      "Epoch 75/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8205 - loss: 0.5289 - val_accuracy: 0.8320 - val_loss: 0.6969 - learning_rate: 6.2500e-05\n",
      "Epoch 76/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8161 - loss: 0.5245 - val_accuracy: 0.8388 - val_loss: 0.6823 - learning_rate: 6.2500e-05\n",
      "Epoch 77/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8339 - loss: 0.4977 - val_accuracy: 0.8427 - val_loss: 0.6696 - learning_rate: 6.2500e-05\n",
      "Epoch 78/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8247 - loss: 0.5014 - val_accuracy: 0.8416 - val_loss: 0.6714 - learning_rate: 6.2500e-05\n",
      "Epoch 79/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8287 - loss: 0.5016 - val_accuracy: 0.8522 - val_loss: 0.6625 - learning_rate: 6.2500e-05\n",
      "Epoch 80/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8352 - loss: 0.4994 - val_accuracy: 0.8629 - val_loss: 0.6372 - learning_rate: 6.2500e-05\n",
      "Epoch 81/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8348 - loss: 0.5188 - val_accuracy: 0.8382 - val_loss: 0.6796 - learning_rate: 6.2500e-05\n",
      "Epoch 82/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8428 - loss: 0.4725 - val_accuracy: 0.8545 - val_loss: 0.6472 - learning_rate: 6.2500e-05\n",
      "Epoch 83/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8344 - loss: 0.4957 - val_accuracy: 0.8506 - val_loss: 0.6449 - learning_rate: 6.2500e-05\n",
      "Epoch 84/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8372 - loss: 0.4732 - val_accuracy: 0.8545 - val_loss: 0.6466 - learning_rate: 3.1250e-05\n",
      "Epoch 85/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8359 - loss: 0.4925 - val_accuracy: 0.8478 - val_loss: 0.6590 - learning_rate: 3.1250e-05\n",
      "Epoch 86/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8445 - loss: 0.4746 - val_accuracy: 0.8517 - val_loss: 0.6387 - learning_rate: 3.1250e-05\n",
      "Epoch 87/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8452 - loss: 0.4684 - val_accuracy: 0.8551 - val_loss: 0.6368 - learning_rate: 1.5625e-05\n",
      "Epoch 88/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8469 - loss: 0.4695 - val_accuracy: 0.8596 - val_loss: 0.6347 - learning_rate: 1.5625e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8493 - loss: 0.4654 - val_accuracy: 0.8562 - val_loss: 0.6380 - learning_rate: 1.5625e-05\n",
      "Epoch 90/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8494 - loss: 0.4521 - val_accuracy: 0.8562 - val_loss: 0.6355 - learning_rate: 1.5625e-05\n",
      "Epoch 91/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8443 - loss: 0.4687 - val_accuracy: 0.8629 - val_loss: 0.6270 - learning_rate: 1.5625e-05\n",
      "Epoch 92/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8441 - loss: 0.4667 - val_accuracy: 0.8562 - val_loss: 0.6355 - learning_rate: 1.5625e-05\n",
      "Epoch 93/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8459 - loss: 0.4680 - val_accuracy: 0.8551 - val_loss: 0.6249 - learning_rate: 1.5625e-05\n",
      "Epoch 94/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8530 - loss: 0.4529 - val_accuracy: 0.8545 - val_loss: 0.6305 - learning_rate: 1.5625e-05\n",
      "Epoch 95/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8471 - loss: 0.4720 - val_accuracy: 0.8607 - val_loss: 0.6208 - learning_rate: 1.5625e-05\n",
      "Epoch 96/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8549 - loss: 0.4633 - val_accuracy: 0.8612 - val_loss: 0.6163 - learning_rate: 1.5625e-05\n",
      "Epoch 97/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8467 - loss: 0.4566 - val_accuracy: 0.8601 - val_loss: 0.6169 - learning_rate: 1.5625e-05\n",
      "Epoch 98/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8485 - loss: 0.4592 - val_accuracy: 0.8556 - val_loss: 0.6202 - learning_rate: 1.5625e-05\n",
      "Epoch 99/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8534 - loss: 0.4537 - val_accuracy: 0.8573 - val_loss: 0.6196 - learning_rate: 1.5625e-05\n",
      "Epoch 100/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8566 - loss: 0.4472 - val_accuracy: 0.8567 - val_loss: 0.6212 - learning_rate: 7.8125e-06\n",
      "Epoch 101/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8500 - loss: 0.4519 - val_accuracy: 0.8590 - val_loss: 0.6144 - learning_rate: 7.8125e-06\n",
      "Epoch 102/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8504 - loss: 0.4512 - val_accuracy: 0.8590 - val_loss: 0.6116 - learning_rate: 7.8125e-06\n",
      "Epoch 103/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8545 - loss: 0.4403 - val_accuracy: 0.8579 - val_loss: 0.6146 - learning_rate: 7.8125e-06\n",
      "Epoch 104/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8599 - loss: 0.4432 - val_accuracy: 0.8584 - val_loss: 0.6135 - learning_rate: 7.8125e-06\n",
      "Epoch 105/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8499 - loss: 0.4606 - val_accuracy: 0.8601 - val_loss: 0.6131 - learning_rate: 7.8125e-06\n",
      "Epoch 106/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8520 - loss: 0.4657 - val_accuracy: 0.8584 - val_loss: 0.6134 - learning_rate: 3.9063e-06\n",
      "Epoch 107/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8531 - loss: 0.4621 - val_accuracy: 0.8607 - val_loss: 0.6116 - learning_rate: 3.9063e-06\n",
      "Epoch 108/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8574 - loss: 0.4593 - val_accuracy: 0.8646 - val_loss: 0.6055 - learning_rate: 3.9063e-06\n",
      "Epoch 109/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8572 - loss: 0.4534 - val_accuracy: 0.8624 - val_loss: 0.6081 - learning_rate: 3.9063e-06\n",
      "Epoch 110/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8599 - loss: 0.4332 - val_accuracy: 0.8618 - val_loss: 0.6103 - learning_rate: 3.9063e-06\n",
      "Epoch 111/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8604 - loss: 0.4385 - val_accuracy: 0.8624 - val_loss: 0.6086 - learning_rate: 3.9063e-06\n",
      "Epoch 112/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8534 - loss: 0.4521 - val_accuracy: 0.8624 - val_loss: 0.6069 - learning_rate: 1.9531e-06\n",
      "Epoch 113/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8673 - loss: 0.4379 - val_accuracy: 0.8618 - val_loss: 0.6086 - learning_rate: 1.9531e-06\n",
      "Epoch 114/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8581 - loss: 0.4473 - val_accuracy: 0.8624 - val_loss: 0.6073 - learning_rate: 1.9531e-06\n",
      "Epoch 115/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8526 - loss: 0.4484 - val_accuracy: 0.8635 - val_loss: 0.6070 - learning_rate: 1.0000e-06\n",
      "Epoch 116/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8488 - loss: 0.4579 - val_accuracy: 0.8652 - val_loss: 0.6057 - learning_rate: 1.0000e-06\n",
      "Epoch 117/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8510 - loss: 0.4440 - val_accuracy: 0.8629 - val_loss: 0.6070 - learning_rate: 1.0000e-06\n",
      "Epoch 118/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8591 - loss: 0.4502 - val_accuracy: 0.8629 - val_loss: 0.6075 - learning_rate: 1.0000e-06\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\n",
      "🧾 Fold 1 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.83      0.98      0.90       423\n",
      "     Jogging       0.90      0.75      0.82       325\n",
      "     Sitting       0.91      0.95      0.93        61\n",
      "    Standing       0.91      0.80      0.85        49\n",
      "    Upstairs       0.91      0.92      0.92       505\n",
      "     Walking       0.81      0.76      0.79       417\n",
      "\n",
      "    accuracy                           0.86      1780\n",
      "   macro avg       0.88      0.86      0.87      1780\n",
      "weighted avg       0.87      0.86      0.86      1780\n",
      "\n",
      "\n",
      "📚 Training Fold 2\n",
      "Epoch 1/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.2982 - loss: 5.1618 - val_accuracy: 0.2500 - val_loss: 3.0877 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.3730 - loss: 2.4609 - val_accuracy: 0.3197 - val_loss: 2.1408 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.4157 - loss: 1.7278 - val_accuracy: 0.3803 - val_loss: 1.7485 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.4300 - loss: 1.4113 - val_accuracy: 0.3494 - val_loss: 1.6951 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4250 - loss: 1.3515 - val_accuracy: 0.4449 - val_loss: 1.4677 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4307 - loss: 1.2829 - val_accuracy: 0.4180 - val_loss: 1.4383 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.4682 - loss: 1.2018 - val_accuracy: 0.4410 - val_loss: 1.3974 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4521 - loss: 1.2189 - val_accuracy: 0.4652 - val_loss: 1.4100 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.4615 - loss: 1.2045 - val_accuracy: 0.4803 - val_loss: 1.4294 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.4660 - loss: 1.2030 - val_accuracy: 0.4669 - val_loss: 1.3562 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4913 - loss: 1.1557 - val_accuracy: 0.4416 - val_loss: 1.3681 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4802 - loss: 1.1660 - val_accuracy: 0.4702 - val_loss: 1.3594 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.4674 - loss: 1.1353 - val_accuracy: 0.4685 - val_loss: 1.3785 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4886 - loss: 1.0992 - val_accuracy: 0.5011 - val_loss: 1.2855 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.4978 - loss: 1.0547 - val_accuracy: 0.4949 - val_loss: 1.2828 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5112 - loss: 1.0242 - val_accuracy: 0.5236 - val_loss: 1.2489 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5386 - loss: 1.0004 - val_accuracy: 0.4972 - val_loss: 1.2643 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5202 - loss: 1.0145 - val_accuracy: 0.5067 - val_loss: 1.2596 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5305 - loss: 0.9847 - val_accuracy: 0.4848 - val_loss: 1.2660 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5334 - loss: 0.9561 - val_accuracy: 0.5337 - val_loss: 1.1889 - learning_rate: 2.5000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.5453 - loss: 0.9310 - val_accuracy: 0.5208 - val_loss: 1.1988 - learning_rate: 2.5000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5483 - loss: 0.9063 - val_accuracy: 0.5360 - val_loss: 1.1872 - learning_rate: 2.5000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5609 - loss: 0.8947 - val_accuracy: 0.5320 - val_loss: 1.1864 - learning_rate: 2.5000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5695 - loss: 0.8903 - val_accuracy: 0.5612 - val_loss: 1.1541 - learning_rate: 2.5000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5709 - loss: 0.8583 - val_accuracy: 0.5770 - val_loss: 1.1281 - learning_rate: 2.5000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5885 - loss: 0.8675 - val_accuracy: 0.5489 - val_loss: 1.1545 - learning_rate: 2.5000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5891 - loss: 0.8477 - val_accuracy: 0.5489 - val_loss: 1.1341 - learning_rate: 2.5000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6039 - loss: 0.8306 - val_accuracy: 0.5798 - val_loss: 1.1169 - learning_rate: 2.5000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6134 - loss: 0.8066 - val_accuracy: 0.5944 - val_loss: 1.1091 - learning_rate: 2.5000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5996 - loss: 0.8462 - val_accuracy: 0.5820 - val_loss: 1.1213 - learning_rate: 2.5000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6090 - loss: 0.8016 - val_accuracy: 0.5893 - val_loss: 1.1035 - learning_rate: 2.5000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6297 - loss: 0.8312 - val_accuracy: 0.6039 - val_loss: 1.0858 - learning_rate: 2.5000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6254 - loss: 0.7863 - val_accuracy: 0.5978 - val_loss: 1.0952 - learning_rate: 2.5000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6331 - loss: 0.7914 - val_accuracy: 0.6298 - val_loss: 1.0592 - learning_rate: 2.5000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6354 - loss: 0.7749 - val_accuracy: 0.6438 - val_loss: 1.0489 - learning_rate: 2.5000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6395 - loss: 0.7779 - val_accuracy: 0.6461 - val_loss: 1.0328 - learning_rate: 2.5000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6284 - loss: 0.7900 - val_accuracy: 0.6320 - val_loss: 1.0461 - learning_rate: 2.5000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6485 - loss: 0.7670 - val_accuracy: 0.6348 - val_loss: 1.0549 - learning_rate: 2.5000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6571 - loss: 0.7501 - val_accuracy: 0.6511 - val_loss: 1.0479 - learning_rate: 2.5000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6815 - loss: 0.7332 - val_accuracy: 0.6820 - val_loss: 0.9911 - learning_rate: 1.2500e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6960 - loss: 0.7165 - val_accuracy: 0.6736 - val_loss: 0.9961 - learning_rate: 1.2500e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6951 - loss: 0.7129 - val_accuracy: 0.7062 - val_loss: 0.9620 - learning_rate: 1.2500e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6933 - loss: 0.7015 - val_accuracy: 0.6831 - val_loss: 0.9719 - learning_rate: 1.2500e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6923 - loss: 0.7253 - val_accuracy: 0.7118 - val_loss: 0.9289 - learning_rate: 1.2500e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7217 - loss: 0.6815 - val_accuracy: 0.7264 - val_loss: 0.9312 - learning_rate: 1.2500e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7224 - loss: 0.6619 - val_accuracy: 0.7247 - val_loss: 0.9144 - learning_rate: 1.2500e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7161 - loss: 0.6716 - val_accuracy: 0.7242 - val_loss: 0.9055 - learning_rate: 1.2500e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7303 - loss: 0.6459 - val_accuracy: 0.7270 - val_loss: 0.8990 - learning_rate: 1.2500e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7368 - loss: 0.6350 - val_accuracy: 0.7427 - val_loss: 0.8674 - learning_rate: 1.2500e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7509 - loss: 0.6333 - val_accuracy: 0.7438 - val_loss: 0.8647 - learning_rate: 1.2500e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7448 - loss: 0.6246 - val_accuracy: 0.7562 - val_loss: 0.8462 - learning_rate: 1.2500e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7505 - loss: 0.6401 - val_accuracy: 0.7629 - val_loss: 0.8353 - learning_rate: 1.2500e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7461 - loss: 0.6413 - val_accuracy: 0.7539 - val_loss: 0.8377 - learning_rate: 1.2500e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7565 - loss: 0.6240 - val_accuracy: 0.7798 - val_loss: 0.8201 - learning_rate: 1.2500e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7625 - loss: 0.5993 - val_accuracy: 0.7573 - val_loss: 0.8417 - learning_rate: 1.2500e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7704 - loss: 0.5926 - val_accuracy: 0.7663 - val_loss: 0.8096 - learning_rate: 1.2500e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7627 - loss: 0.5989 - val_accuracy: 0.7669 - val_loss: 0.8048 - learning_rate: 1.2500e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7802 - loss: 0.5802 - val_accuracy: 0.7742 - val_loss: 0.8102 - learning_rate: 1.2500e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7744 - loss: 0.5864 - val_accuracy: 0.7882 - val_loss: 0.7722 - learning_rate: 1.2500e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7889 - loss: 0.5641 - val_accuracy: 0.8000 - val_loss: 0.7619 - learning_rate: 1.2500e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7771 - loss: 0.5688 - val_accuracy: 0.8017 - val_loss: 0.7440 - learning_rate: 1.2500e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7967 - loss: 0.5601 - val_accuracy: 0.7938 - val_loss: 0.7634 - learning_rate: 1.2500e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7862 - loss: 0.5698 - val_accuracy: 0.8039 - val_loss: 0.7435 - learning_rate: 1.2500e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7890 - loss: 0.5700 - val_accuracy: 0.8062 - val_loss: 0.7374 - learning_rate: 1.2500e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7944 - loss: 0.5640 - val_accuracy: 0.7809 - val_loss: 0.7551 - learning_rate: 1.2500e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8061 - loss: 0.5354 - val_accuracy: 0.7921 - val_loss: 0.7374 - learning_rate: 1.2500e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7984 - loss: 0.5483 - val_accuracy: 0.8079 - val_loss: 0.7227 - learning_rate: 1.2500e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7875 - loss: 0.5667 - val_accuracy: 0.8185 - val_loss: 0.6977 - learning_rate: 1.2500e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8200 - loss: 0.5053 - val_accuracy: 0.7944 - val_loss: 0.7385 - learning_rate: 1.2500e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8191 - loss: 0.5273 - val_accuracy: 0.8174 - val_loss: 0.7088 - learning_rate: 1.2500e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8139 - loss: 0.5293 - val_accuracy: 0.8292 - val_loss: 0.6811 - learning_rate: 1.2500e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8191 - loss: 0.5434 - val_accuracy: 0.8101 - val_loss: 0.6884 - learning_rate: 1.2500e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8293 - loss: 0.5001 - val_accuracy: 0.8174 - val_loss: 0.6851 - learning_rate: 1.2500e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8172 - loss: 0.5424 - val_accuracy: 0.8084 - val_loss: 0.6948 - learning_rate: 1.2500e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8234 - loss: 0.4974 - val_accuracy: 0.8152 - val_loss: 0.6729 - learning_rate: 6.2500e-05\n",
      "Epoch 76/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8273 - loss: 0.5073 - val_accuracy: 0.8264 - val_loss: 0.6603 - learning_rate: 6.2500e-05\n",
      "Epoch 77/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.8434 - loss: 0.4827 - val_accuracy: 0.8275 - val_loss: 0.6535 - learning_rate: 6.2500e-05\n",
      "Epoch 78/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8451 - loss: 0.4715 - val_accuracy: 0.8264 - val_loss: 0.6560 - learning_rate: 6.2500e-05\n",
      "Epoch 79/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8456 - loss: 0.4774 - val_accuracy: 0.8287 - val_loss: 0.6600 - learning_rate: 6.2500e-05\n",
      "Epoch 80/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8460 - loss: 0.4621 - val_accuracy: 0.8360 - val_loss: 0.6499 - learning_rate: 6.2500e-05\n",
      "Epoch 81/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8459 - loss: 0.4759 - val_accuracy: 0.8315 - val_loss: 0.6527 - learning_rate: 6.2500e-05\n",
      "Epoch 82/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8406 - loss: 0.4685 - val_accuracy: 0.8292 - val_loss: 0.6437 - learning_rate: 6.2500e-05\n",
      "Epoch 83/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8425 - loss: 0.4752 - val_accuracy: 0.8320 - val_loss: 0.6320 - learning_rate: 6.2500e-05\n",
      "Epoch 84/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8459 - loss: 0.4706 - val_accuracy: 0.8371 - val_loss: 0.6248 - learning_rate: 6.2500e-05\n",
      "Epoch 85/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8481 - loss: 0.4679 - val_accuracy: 0.8433 - val_loss: 0.6247 - learning_rate: 6.2500e-05\n",
      "Epoch 86/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8537 - loss: 0.4525 - val_accuracy: 0.8438 - val_loss: 0.6178 - learning_rate: 6.2500e-05\n",
      "Epoch 87/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8507 - loss: 0.4492 - val_accuracy: 0.8438 - val_loss: 0.6108 - learning_rate: 6.2500e-05\n",
      "Epoch 88/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8585 - loss: 0.4488 - val_accuracy: 0.8416 - val_loss: 0.6218 - learning_rate: 6.2500e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8562 - loss: 0.4616 - val_accuracy: 0.8298 - val_loss: 0.6474 - learning_rate: 6.2500e-05\n",
      "Epoch 90/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8645 - loss: 0.4422 - val_accuracy: 0.8298 - val_loss: 0.6272 - learning_rate: 6.2500e-05\n",
      "Epoch 91/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8690 - loss: 0.4245 - val_accuracy: 0.8421 - val_loss: 0.6032 - learning_rate: 3.1250e-05\n",
      "Epoch 92/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8653 - loss: 0.4239 - val_accuracy: 0.8466 - val_loss: 0.6049 - learning_rate: 3.1250e-05\n",
      "Epoch 93/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8594 - loss: 0.4414 - val_accuracy: 0.8433 - val_loss: 0.6177 - learning_rate: 3.1250e-05\n",
      "Epoch 94/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8668 - loss: 0.4292 - val_accuracy: 0.8483 - val_loss: 0.6010 - learning_rate: 3.1250e-05\n",
      "Epoch 95/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8673 - loss: 0.4242 - val_accuracy: 0.8517 - val_loss: 0.5935 - learning_rate: 3.1250e-05\n",
      "Epoch 96/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8698 - loss: 0.4142 - val_accuracy: 0.8388 - val_loss: 0.6055 - learning_rate: 3.1250e-05\n",
      "Epoch 97/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8694 - loss: 0.4162 - val_accuracy: 0.8472 - val_loss: 0.6023 - learning_rate: 3.1250e-05\n",
      "Epoch 98/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8693 - loss: 0.4158 - val_accuracy: 0.8466 - val_loss: 0.5947 - learning_rate: 3.1250e-05\n",
      "Epoch 99/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8729 - loss: 0.4200 - val_accuracy: 0.8489 - val_loss: 0.5902 - learning_rate: 1.5625e-05\n",
      "Epoch 100/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8766 - loss: 0.3979 - val_accuracy: 0.8404 - val_loss: 0.6030 - learning_rate: 1.5625e-05\n",
      "Epoch 101/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8719 - loss: 0.3952 - val_accuracy: 0.8500 - val_loss: 0.5866 - learning_rate: 1.5625e-05\n",
      "Epoch 102/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8717 - loss: 0.4042 - val_accuracy: 0.8438 - val_loss: 0.5941 - learning_rate: 1.5625e-05\n",
      "Epoch 103/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8753 - loss: 0.4101 - val_accuracy: 0.8517 - val_loss: 0.5860 - learning_rate: 1.5625e-05\n",
      "Epoch 104/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8760 - loss: 0.4049 - val_accuracy: 0.8444 - val_loss: 0.5929 - learning_rate: 1.5625e-05\n",
      "Epoch 105/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8742 - loss: 0.4028 - val_accuracy: 0.8472 - val_loss: 0.5950 - learning_rate: 1.5625e-05\n",
      "Epoch 106/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8743 - loss: 0.4069 - val_accuracy: 0.8466 - val_loss: 0.5902 - learning_rate: 1.5625e-05\n",
      "Epoch 107/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8717 - loss: 0.4215 - val_accuracy: 0.8455 - val_loss: 0.5920 - learning_rate: 7.8125e-06\n",
      "Epoch 108/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8826 - loss: 0.3973 - val_accuracy: 0.8483 - val_loss: 0.5880 - learning_rate: 7.8125e-06\n",
      "Epoch 109/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8782 - loss: 0.4019 - val_accuracy: 0.8472 - val_loss: 0.5866 - learning_rate: 7.8125e-06\n",
      "Epoch 110/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8697 - loss: 0.4131 - val_accuracy: 0.8466 - val_loss: 0.5891 - learning_rate: 3.9063e-06\n",
      "Epoch 111/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8748 - loss: 0.4052 - val_accuracy: 0.8489 - val_loss: 0.5876 - learning_rate: 3.9063e-06\n",
      "Epoch 112/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8796 - loss: 0.3960 - val_accuracy: 0.8489 - val_loss: 0.5856 - learning_rate: 3.9063e-06\n",
      "Epoch 113/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8700 - loss: 0.4034 - val_accuracy: 0.8489 - val_loss: 0.5867 - learning_rate: 3.9063e-06\n",
      "Epoch 114/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8691 - loss: 0.4047 - val_accuracy: 0.8466 - val_loss: 0.5924 - learning_rate: 3.9063e-06\n",
      "Epoch 115/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8732 - loss: 0.4023 - val_accuracy: 0.8478 - val_loss: 0.5892 - learning_rate: 3.9063e-06\n",
      "Epoch 116/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8763 - loss: 0.3998 - val_accuracy: 0.8478 - val_loss: 0.5876 - learning_rate: 1.9531e-06\n",
      "Epoch 117/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8797 - loss: 0.4045 - val_accuracy: 0.8478 - val_loss: 0.5866 - learning_rate: 1.9531e-06\n",
      "Epoch 118/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8790 - loss: 0.3983 - val_accuracy: 0.8500 - val_loss: 0.5865 - learning_rate: 1.9531e-06\n",
      "Epoch 119/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8793 - loss: 0.3946 - val_accuracy: 0.8506 - val_loss: 0.5865 - learning_rate: 1.0000e-06\n",
      "Epoch 120/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8685 - loss: 0.4015 - val_accuracy: 0.8500 - val_loss: 0.5886 - learning_rate: 1.0000e-06\n",
      "Epoch 121/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8728 - loss: 0.4150 - val_accuracy: 0.8483 - val_loss: 0.5882 - learning_rate: 1.0000e-06\n",
      "Epoch 122/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8737 - loss: 0.4098 - val_accuracy: 0.8478 - val_loss: 0.5882 - learning_rate: 1.0000e-06\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "🧾 Fold 2 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.89      0.96      0.93       422\n",
      "     Jogging       0.88      0.70      0.78       325\n",
      "     Sitting       0.93      0.87      0.90        62\n",
      "    Standing       0.75      0.82      0.78        49\n",
      "    Upstairs       0.85      0.97      0.91       506\n",
      "     Walking       0.78      0.69      0.73       416\n",
      "\n",
      "    accuracy                           0.85      1780\n",
      "   macro avg       0.85      0.84      0.84      1780\n",
      "weighted avg       0.85      0.85      0.84      1780\n",
      "\n",
      "\n",
      "📚 Training Fold 3\n",
      "Epoch 1/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.2858 - loss: 5.1765 - val_accuracy: 0.2478 - val_loss: 3.1541 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.3691 - loss: 2.5531 - val_accuracy: 0.3438 - val_loss: 2.1697 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4169 - loss: 1.7610 - val_accuracy: 0.3640 - val_loss: 1.7146 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4228 - loss: 1.4897 - val_accuracy: 0.4140 - val_loss: 1.5677 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4394 - loss: 1.3378 - val_accuracy: 0.4303 - val_loss: 1.4831 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4486 - loss: 1.2609 - val_accuracy: 0.4534 - val_loss: 1.3904 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.4467 - loss: 1.2186 - val_accuracy: 0.4674 - val_loss: 1.3628 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4525 - loss: 1.2425 - val_accuracy: 0.4618 - val_loss: 1.3648 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4756 - loss: 1.2214 - val_accuracy: 0.4590 - val_loss: 1.3444 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4746 - loss: 1.1835 - val_accuracy: 0.4871 - val_loss: 1.3147 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.4719 - loss: 1.1281 - val_accuracy: 0.5039 - val_loss: 1.3244 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4658 - loss: 1.1558 - val_accuracy: 0.4680 - val_loss: 1.3684 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4740 - loss: 1.2051 - val_accuracy: 0.4899 - val_loss: 1.3309 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4912 - loss: 1.1061 - val_accuracy: 0.5028 - val_loss: 1.2731 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5226 - loss: 1.0350 - val_accuracy: 0.5107 - val_loss: 1.2654 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5173 - loss: 1.0196 - val_accuracy: 0.5079 - val_loss: 1.2318 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4924 - loss: 1.0595 - val_accuracy: 0.5112 - val_loss: 1.2356 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5171 - loss: 0.9939 - val_accuracy: 0.5191 - val_loss: 1.2226 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.5052 - loss: 1.0190 - val_accuracy: 0.5129 - val_loss: 1.2288 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5252 - loss: 1.0045 - val_accuracy: 0.5180 - val_loss: 1.2125 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5417 - loss: 0.9975 - val_accuracy: 0.5208 - val_loss: 1.2330 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5261 - loss: 1.0048 - val_accuracy: 0.5624 - val_loss: 1.2068 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.5386 - loss: 0.9909 - val_accuracy: 0.5118 - val_loss: 1.2377 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5548 - loss: 0.9392 - val_accuracy: 0.5309 - val_loss: 1.2164 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.5543 - loss: 0.9744 - val_accuracy: 0.5343 - val_loss: 1.2296 - learning_rate: 5.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.5620 - loss: 0.9423 - val_accuracy: 0.5590 - val_loss: 1.1640 - learning_rate: 2.5000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.5785 - loss: 0.8893 - val_accuracy: 0.5612 - val_loss: 1.1636 - learning_rate: 2.5000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5771 - loss: 0.8731 - val_accuracy: 0.5770 - val_loss: 1.1279 - learning_rate: 2.5000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5925 - loss: 0.8509 - val_accuracy: 0.5815 - val_loss: 1.1201 - learning_rate: 2.5000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.5869 - loss: 0.8496 - val_accuracy: 0.6028 - val_loss: 1.0894 - learning_rate: 2.5000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.6171 - loss: 0.8369 - val_accuracy: 0.6090 - val_loss: 1.1011 - learning_rate: 2.5000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.5912 - loss: 0.8873 - val_accuracy: 0.5787 - val_loss: 1.1264 - learning_rate: 2.5000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.5891 - loss: 0.8353 - val_accuracy: 0.6051 - val_loss: 1.0999 - learning_rate: 2.5000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6166 - loss: 0.8187 - val_accuracy: 0.6140 - val_loss: 1.0628 - learning_rate: 1.2500e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6112 - loss: 0.7916 - val_accuracy: 0.6213 - val_loss: 1.0664 - learning_rate: 1.2500e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6263 - loss: 0.7955 - val_accuracy: 0.6270 - val_loss: 1.0436 - learning_rate: 1.2500e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6339 - loss: 0.7697 - val_accuracy: 0.6011 - val_loss: 1.0611 - learning_rate: 1.2500e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6436 - loss: 0.7609 - val_accuracy: 0.6298 - val_loss: 1.0480 - learning_rate: 1.2500e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6534 - loss: 0.7430 - val_accuracy: 0.6579 - val_loss: 0.9936 - learning_rate: 1.2500e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6640 - loss: 0.7293 - val_accuracy: 0.6556 - val_loss: 0.9978 - learning_rate: 1.2500e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6634 - loss: 0.7134 - val_accuracy: 0.6657 - val_loss: 0.9839 - learning_rate: 1.2500e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.6649 - loss: 0.7251 - val_accuracy: 0.6702 - val_loss: 0.9958 - learning_rate: 1.2500e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6763 - loss: 0.7156 - val_accuracy: 0.6775 - val_loss: 0.9691 - learning_rate: 1.2500e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6798 - loss: 0.7113 - val_accuracy: 0.6809 - val_loss: 0.9612 - learning_rate: 1.2500e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6666 - loss: 0.7161 - val_accuracy: 0.6753 - val_loss: 0.9561 - learning_rate: 1.2500e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6918 - loss: 0.6960 - val_accuracy: 0.6753 - val_loss: 0.9554 - learning_rate: 1.2500e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6742 - loss: 0.7133 - val_accuracy: 0.6674 - val_loss: 0.9711 - learning_rate: 1.2500e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6881 - loss: 0.7072 - val_accuracy: 0.7039 - val_loss: 0.9330 - learning_rate: 1.2500e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7070 - loss: 0.6925 - val_accuracy: 0.6983 - val_loss: 0.9222 - learning_rate: 1.2500e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7156 - loss: 0.6589 - val_accuracy: 0.7079 - val_loss: 0.9117 - learning_rate: 1.2500e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7179 - loss: 0.6598 - val_accuracy: 0.7056 - val_loss: 0.8982 - learning_rate: 1.2500e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.7106 - loss: 0.6604 - val_accuracy: 0.7253 - val_loss: 0.8898 - learning_rate: 1.2500e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7240 - loss: 0.6626 - val_accuracy: 0.7073 - val_loss: 0.8957 - learning_rate: 1.2500e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7312 - loss: 0.6405 - val_accuracy: 0.6944 - val_loss: 0.9188 - learning_rate: 1.2500e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7302 - loss: 0.6357 - val_accuracy: 0.7275 - val_loss: 0.8750 - learning_rate: 1.2500e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7336 - loss: 0.6427 - val_accuracy: 0.7326 - val_loss: 0.8579 - learning_rate: 1.2500e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7413 - loss: 0.6178 - val_accuracy: 0.7326 - val_loss: 0.8624 - learning_rate: 1.2500e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7383 - loss: 0.6207 - val_accuracy: 0.7219 - val_loss: 0.8801 - learning_rate: 1.2500e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7463 - loss: 0.6304 - val_accuracy: 0.7185 - val_loss: 0.8846 - learning_rate: 1.2500e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7613 - loss: 0.6077 - val_accuracy: 0.7798 - val_loss: 0.8116 - learning_rate: 6.2500e-05\n",
      "Epoch 61/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7686 - loss: 0.5930 - val_accuracy: 0.7691 - val_loss: 0.8157 - learning_rate: 6.2500e-05\n",
      "Epoch 62/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7751 - loss: 0.5798 - val_accuracy: 0.7708 - val_loss: 0.8004 - learning_rate: 6.2500e-05\n",
      "Epoch 63/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7742 - loss: 0.5817 - val_accuracy: 0.7646 - val_loss: 0.7921 - learning_rate: 6.2500e-05\n",
      "Epoch 64/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7762 - loss: 0.5823 - val_accuracy: 0.7719 - val_loss: 0.7936 - learning_rate: 6.2500e-05\n",
      "Epoch 65/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7773 - loss: 0.5678 - val_accuracy: 0.7854 - val_loss: 0.7778 - learning_rate: 6.2500e-05\n",
      "Epoch 66/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7896 - loss: 0.5542 - val_accuracy: 0.7983 - val_loss: 0.7554 - learning_rate: 6.2500e-05\n",
      "Epoch 67/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7904 - loss: 0.5443 - val_accuracy: 0.8028 - val_loss: 0.7520 - learning_rate: 6.2500e-05\n",
      "Epoch 68/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7890 - loss: 0.5588 - val_accuracy: 0.7854 - val_loss: 0.7642 - learning_rate: 6.2500e-05\n",
      "Epoch 69/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8028 - loss: 0.5207 - val_accuracy: 0.7865 - val_loss: 0.7720 - learning_rate: 6.2500e-05\n",
      "Epoch 70/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7937 - loss: 0.5422 - val_accuracy: 0.7888 - val_loss: 0.7565 - learning_rate: 6.2500e-05\n",
      "Epoch 71/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8008 - loss: 0.5329 - val_accuracy: 0.7910 - val_loss: 0.7479 - learning_rate: 3.1250e-05\n",
      "Epoch 72/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8028 - loss: 0.5217 - val_accuracy: 0.7966 - val_loss: 0.7401 - learning_rate: 3.1250e-05\n",
      "Epoch 73/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8124 - loss: 0.5168 - val_accuracy: 0.8124 - val_loss: 0.7228 - learning_rate: 3.1250e-05\n",
      "Epoch 74/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8004 - loss: 0.5292 - val_accuracy: 0.8157 - val_loss: 0.7197 - learning_rate: 3.1250e-05\n",
      "Epoch 75/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8123 - loss: 0.5064 - val_accuracy: 0.8039 - val_loss: 0.7107 - learning_rate: 3.1250e-05\n",
      "Epoch 76/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8020 - loss: 0.5253 - val_accuracy: 0.8079 - val_loss: 0.7047 - learning_rate: 3.1250e-05\n",
      "Epoch 77/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8141 - loss: 0.5151 - val_accuracy: 0.8213 - val_loss: 0.7062 - learning_rate: 3.1250e-05\n",
      "Epoch 78/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8187 - loss: 0.4978 - val_accuracy: 0.8180 - val_loss: 0.7012 - learning_rate: 3.1250e-05\n",
      "Epoch 79/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8097 - loss: 0.5307 - val_accuracy: 0.8146 - val_loss: 0.6944 - learning_rate: 3.1250e-05\n",
      "Epoch 80/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8167 - loss: 0.5065 - val_accuracy: 0.8242 - val_loss: 0.6974 - learning_rate: 3.1250e-05\n",
      "Epoch 81/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8174 - loss: 0.5074 - val_accuracy: 0.8197 - val_loss: 0.6891 - learning_rate: 3.1250e-05\n",
      "Epoch 82/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8238 - loss: 0.4960 - val_accuracy: 0.8208 - val_loss: 0.6925 - learning_rate: 3.1250e-05\n",
      "Epoch 83/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8202 - loss: 0.5008 - val_accuracy: 0.8135 - val_loss: 0.6975 - learning_rate: 3.1250e-05\n",
      "Epoch 84/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8198 - loss: 0.5099 - val_accuracy: 0.8118 - val_loss: 0.6981 - learning_rate: 3.1250e-05\n",
      "Epoch 85/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8212 - loss: 0.5012 - val_accuracy: 0.8287 - val_loss: 0.6817 - learning_rate: 1.5625e-05\n",
      "Epoch 86/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8205 - loss: 0.5020 - val_accuracy: 0.8320 - val_loss: 0.6757 - learning_rate: 1.5625e-05\n",
      "Epoch 87/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8293 - loss: 0.4887 - val_accuracy: 0.8348 - val_loss: 0.6687 - learning_rate: 1.5625e-05\n",
      "Epoch 88/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8171 - loss: 0.4929 - val_accuracy: 0.8348 - val_loss: 0.6753 - learning_rate: 1.5625e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8175 - loss: 0.5096 - val_accuracy: 0.8247 - val_loss: 0.6825 - learning_rate: 1.5625e-05\n",
      "Epoch 90/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8353 - loss: 0.4765 - val_accuracy: 0.8320 - val_loss: 0.6646 - learning_rate: 1.5625e-05\n",
      "Epoch 91/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8336 - loss: 0.4729 - val_accuracy: 0.8348 - val_loss: 0.6652 - learning_rate: 1.5625e-05\n",
      "Epoch 92/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8286 - loss: 0.4833 - val_accuracy: 0.8410 - val_loss: 0.6547 - learning_rate: 1.5625e-05\n",
      "Epoch 93/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8316 - loss: 0.4770 - val_accuracy: 0.8326 - val_loss: 0.6644 - learning_rate: 1.5625e-05\n",
      "Epoch 94/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8216 - loss: 0.4879 - val_accuracy: 0.8348 - val_loss: 0.6635 - learning_rate: 1.5625e-05\n",
      "Epoch 95/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8327 - loss: 0.4957 - val_accuracy: 0.8376 - val_loss: 0.6652 - learning_rate: 1.5625e-05\n",
      "Epoch 96/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8304 - loss: 0.4781 - val_accuracy: 0.8399 - val_loss: 0.6581 - learning_rate: 7.8125e-06\n",
      "Epoch 97/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8265 - loss: 0.4905 - val_accuracy: 0.8354 - val_loss: 0.6614 - learning_rate: 7.8125e-06\n",
      "Epoch 98/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8199 - loss: 0.4859 - val_accuracy: 0.8444 - val_loss: 0.6553 - learning_rate: 7.8125e-06\n",
      "Epoch 99/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8303 - loss: 0.4754 - val_accuracy: 0.8393 - val_loss: 0.6557 - learning_rate: 3.9063e-06\n",
      "Epoch 100/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8303 - loss: 0.4748 - val_accuracy: 0.8382 - val_loss: 0.6563 - learning_rate: 3.9063e-06\n",
      "Epoch 101/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8323 - loss: 0.4759 - val_accuracy: 0.8360 - val_loss: 0.6590 - learning_rate: 3.9063e-06\n",
      "Epoch 102/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8322 - loss: 0.4699 - val_accuracy: 0.8410 - val_loss: 0.6551 - learning_rate: 1.9531e-06\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\n",
      "🧾 Fold 3 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.84      0.97      0.90       422\n",
      "     Jogging       0.88      0.73      0.80       325\n",
      "     Sitting       0.87      0.85      0.86        61\n",
      "    Standing       0.73      0.70      0.71        50\n",
      "    Upstairs       0.90      0.88      0.89       506\n",
      "     Walking       0.76      0.77      0.77       416\n",
      "\n",
      "    accuracy                           0.84      1780\n",
      "   macro avg       0.83      0.82      0.82      1780\n",
      "weighted avg       0.84      0.84      0.84      1780\n",
      "\n",
      "\n",
      "📚 Training Fold 4\n",
      "Epoch 1/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.2923 - loss: 5.2383 - val_accuracy: 0.2597 - val_loss: 3.2178 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.3964 - loss: 2.5333 - val_accuracy: 0.3991 - val_loss: 2.1429 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4163 - loss: 1.7976 - val_accuracy: 0.4042 - val_loss: 1.7728 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4372 - loss: 1.4867 - val_accuracy: 0.4340 - val_loss: 1.5422 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.4301 - loss: 1.3573 - val_accuracy: 0.4340 - val_loss: 1.4579 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4464 - loss: 1.2813 - val_accuracy: 0.4002 - val_loss: 1.5055 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4445 - loss: 1.2584 - val_accuracy: 0.4576 - val_loss: 1.4262 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4654 - loss: 1.2025 - val_accuracy: 0.4626 - val_loss: 1.3829 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4746 - loss: 1.1740 - val_accuracy: 0.4699 - val_loss: 1.3807 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4761 - loss: 1.1815 - val_accuracy: 0.4834 - val_loss: 1.3540 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4671 - loss: 1.2093 - val_accuracy: 0.4592 - val_loss: 1.3860 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4743 - loss: 1.1523 - val_accuracy: 0.4525 - val_loss: 1.4181 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4933 - loss: 1.1398 - val_accuracy: 0.4840 - val_loss: 1.3479 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4969 - loss: 1.1126 - val_accuracy: 0.4677 - val_loss: 1.3818 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.4798 - loss: 1.1599 - val_accuracy: 0.4739 - val_loss: 1.3733 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.4849 - loss: 1.1388 - val_accuracy: 0.4694 - val_loss: 1.3563 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.5089 - loss: 1.0709 - val_accuracy: 0.4986 - val_loss: 1.2906 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5174 - loss: 1.0239 - val_accuracy: 0.5087 - val_loss: 1.2703 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.5151 - loss: 1.0069 - val_accuracy: 0.4890 - val_loss: 1.2761 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5197 - loss: 1.0277 - val_accuracy: 0.5008 - val_loss: 1.2808 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5285 - loss: 1.0171 - val_accuracy: 0.4958 - val_loss: 1.2862 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.5462 - loss: 0.9533 - val_accuracy: 0.5166 - val_loss: 1.2307 - learning_rate: 2.5000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5415 - loss: 0.9337 - val_accuracy: 0.5250 - val_loss: 1.2176 - learning_rate: 2.5000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.5523 - loss: 0.8845 - val_accuracy: 0.5323 - val_loss: 1.2042 - learning_rate: 2.5000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5670 - loss: 0.8854 - val_accuracy: 0.5481 - val_loss: 1.1872 - learning_rate: 2.5000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.5758 - loss: 0.8697 - val_accuracy: 0.5492 - val_loss: 1.1700 - learning_rate: 2.5000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5702 - loss: 0.8620 - val_accuracy: 0.5520 - val_loss: 1.1673 - learning_rate: 2.5000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5913 - loss: 0.8529 - val_accuracy: 0.5745 - val_loss: 1.1526 - learning_rate: 2.5000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5991 - loss: 0.8263 - val_accuracy: 0.5649 - val_loss: 1.1489 - learning_rate: 2.5000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.5923 - loss: 0.8530 - val_accuracy: 0.5644 - val_loss: 1.1750 - learning_rate: 2.5000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.6058 - loss: 0.8164 - val_accuracy: 0.5829 - val_loss: 1.1345 - learning_rate: 2.5000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6182 - loss: 0.8114 - val_accuracy: 0.5700 - val_loss: 1.1492 - learning_rate: 2.5000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6221 - loss: 0.7931 - val_accuracy: 0.5908 - val_loss: 1.1166 - learning_rate: 2.5000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6247 - loss: 0.8010 - val_accuracy: 0.5970 - val_loss: 1.1121 - learning_rate: 2.5000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6216 - loss: 0.7931 - val_accuracy: 0.5981 - val_loss: 1.1043 - learning_rate: 2.5000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6462 - loss: 0.7674 - val_accuracy: 0.6099 - val_loss: 1.0939 - learning_rate: 2.5000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6309 - loss: 0.7812 - val_accuracy: 0.6178 - val_loss: 1.0920 - learning_rate: 2.5000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6570 - loss: 0.7515 - val_accuracy: 0.6178 - val_loss: 1.1074 - learning_rate: 2.5000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6289 - loss: 0.7520 - val_accuracy: 0.5958 - val_loss: 1.1390 - learning_rate: 2.5000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6413 - loss: 0.7859 - val_accuracy: 0.6183 - val_loss: 1.0707 - learning_rate: 2.5000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6573 - loss: 0.7555 - val_accuracy: 0.6234 - val_loss: 1.0633 - learning_rate: 2.5000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6520 - loss: 0.7608 - val_accuracy: 0.6498 - val_loss: 1.0328 - learning_rate: 2.5000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6555 - loss: 0.7357 - val_accuracy: 0.6273 - val_loss: 1.0670 - learning_rate: 2.5000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.6813 - loss: 0.7193 - val_accuracy: 0.6279 - val_loss: 1.0543 - learning_rate: 2.5000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6690 - loss: 0.7656 - val_accuracy: 0.6313 - val_loss: 1.0701 - learning_rate: 2.5000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.6799 - loss: 0.7495 - val_accuracy: 0.6914 - val_loss: 0.9943 - learning_rate: 1.2500e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.6938 - loss: 0.6971 - val_accuracy: 0.6757 - val_loss: 1.0058 - learning_rate: 1.2500e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7112 - loss: 0.6790 - val_accuracy: 0.6773 - val_loss: 0.9784 - learning_rate: 1.2500e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.7125 - loss: 0.6749 - val_accuracy: 0.6981 - val_loss: 0.9671 - learning_rate: 1.2500e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7239 - loss: 0.6672 - val_accuracy: 0.6824 - val_loss: 0.9657 - learning_rate: 1.2500e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7205 - loss: 0.6500 - val_accuracy: 0.7021 - val_loss: 0.9555 - learning_rate: 1.2500e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7302 - loss: 0.6626 - val_accuracy: 0.7133 - val_loss: 0.9265 - learning_rate: 1.2500e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7343 - loss: 0.6488 - val_accuracy: 0.7223 - val_loss: 0.9242 - learning_rate: 1.2500e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7472 - loss: 0.6397 - val_accuracy: 0.7307 - val_loss: 0.9142 - learning_rate: 1.2500e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7491 - loss: 0.6143 - val_accuracy: 0.7105 - val_loss: 0.9226 - learning_rate: 1.2500e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7453 - loss: 0.6138 - val_accuracy: 0.7246 - val_loss: 0.9027 - learning_rate: 1.2500e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7547 - loss: 0.6129 - val_accuracy: 0.7263 - val_loss: 0.8994 - learning_rate: 1.2500e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7633 - loss: 0.5988 - val_accuracy: 0.7291 - val_loss: 0.9034 - learning_rate: 1.2500e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7575 - loss: 0.6219 - val_accuracy: 0.7437 - val_loss: 0.8772 - learning_rate: 1.2500e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7688 - loss: 0.5881 - val_accuracy: 0.7482 - val_loss: 0.8756 - learning_rate: 1.2500e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7747 - loss: 0.5777 - val_accuracy: 0.7499 - val_loss: 0.8531 - learning_rate: 1.2500e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7768 - loss: 0.5940 - val_accuracy: 0.7527 - val_loss: 0.8559 - learning_rate: 1.2500e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7773 - loss: 0.5834 - val_accuracy: 0.7707 - val_loss: 0.8342 - learning_rate: 1.2500e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7851 - loss: 0.5839 - val_accuracy: 0.7560 - val_loss: 0.8391 - learning_rate: 1.2500e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.7715 - loss: 0.5795 - val_accuracy: 0.7830 - val_loss: 0.8252 - learning_rate: 1.2500e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7786 - loss: 0.5835 - val_accuracy: 0.7841 - val_loss: 0.8071 - learning_rate: 1.2500e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7772 - loss: 0.5591 - val_accuracy: 0.7707 - val_loss: 0.8233 - learning_rate: 1.2500e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7917 - loss: 0.5611 - val_accuracy: 0.7808 - val_loss: 0.7973 - learning_rate: 1.2500e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8032 - loss: 0.5509 - val_accuracy: 0.8010 - val_loss: 0.7907 - learning_rate: 1.2500e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7959 - loss: 0.5661 - val_accuracy: 0.7926 - val_loss: 0.7872 - learning_rate: 1.2500e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7904 - loss: 0.5528 - val_accuracy: 0.7982 - val_loss: 0.7940 - learning_rate: 1.2500e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8118 - loss: 0.5347 - val_accuracy: 0.8010 - val_loss: 0.7798 - learning_rate: 1.2500e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7990 - loss: 0.5599 - val_accuracy: 0.8027 - val_loss: 0.7737 - learning_rate: 1.2500e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.5252 - val_accuracy: 0.7988 - val_loss: 0.7659 - learning_rate: 1.2500e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8137 - loss: 0.5216 - val_accuracy: 0.8066 - val_loss: 0.7490 - learning_rate: 1.2500e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8104 - loss: 0.5237 - val_accuracy: 0.7999 - val_loss: 0.7504 - learning_rate: 1.2500e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8176 - loss: 0.5202 - val_accuracy: 0.8072 - val_loss: 0.7565 - learning_rate: 1.2500e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8238 - loss: 0.5116 - val_accuracy: 0.8128 - val_loss: 0.7590 - learning_rate: 1.2500e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8311 - loss: 0.5032 - val_accuracy: 0.8286 - val_loss: 0.7216 - learning_rate: 6.2500e-05\n",
      "Epoch 80/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8212 - loss: 0.5011 - val_accuracy: 0.8269 - val_loss: 0.7166 - learning_rate: 6.2500e-05\n",
      "Epoch 81/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8362 - loss: 0.4869 - val_accuracy: 0.8196 - val_loss: 0.7111 - learning_rate: 6.2500e-05\n",
      "Epoch 82/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.8321 - loss: 0.4833 - val_accuracy: 0.8286 - val_loss: 0.7064 - learning_rate: 6.2500e-05\n",
      "Epoch 83/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8332 - loss: 0.4819 - val_accuracy: 0.8308 - val_loss: 0.6968 - learning_rate: 6.2500e-05\n",
      "Epoch 84/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8395 - loss: 0.4720 - val_accuracy: 0.8286 - val_loss: 0.7055 - learning_rate: 6.2500e-05\n",
      "Epoch 85/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8460 - loss: 0.4688 - val_accuracy: 0.8359 - val_loss: 0.6980 - learning_rate: 6.2500e-05\n",
      "Epoch 86/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8545 - loss: 0.4619 - val_accuracy: 0.8347 - val_loss: 0.6913 - learning_rate: 6.2500e-05\n",
      "Epoch 87/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8474 - loss: 0.4717 - val_accuracy: 0.8336 - val_loss: 0.6888 - learning_rate: 6.2500e-05\n",
      "Epoch 88/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8420 - loss: 0.4645 - val_accuracy: 0.8302 - val_loss: 0.7060 - learning_rate: 6.2500e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8444 - loss: 0.4922 - val_accuracy: 0.8375 - val_loss: 0.6821 - learning_rate: 6.2500e-05\n",
      "Epoch 90/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.8460 - loss: 0.4601 - val_accuracy: 0.8392 - val_loss: 0.6924 - learning_rate: 6.2500e-05\n",
      "Epoch 91/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8479 - loss: 0.4539 - val_accuracy: 0.8404 - val_loss: 0.6754 - learning_rate: 6.2500e-05\n",
      "Epoch 92/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.8533 - loss: 0.4604 - val_accuracy: 0.8319 - val_loss: 0.6869 - learning_rate: 6.2500e-05\n",
      "Epoch 93/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.8387 - loss: 0.4753 - val_accuracy: 0.8409 - val_loss: 0.6794 - learning_rate: 6.2500e-05\n",
      "Epoch 94/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8493 - loss: 0.4529 - val_accuracy: 0.8527 - val_loss: 0.6591 - learning_rate: 6.2500e-05\n",
      "Epoch 95/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8529 - loss: 0.4526 - val_accuracy: 0.8477 - val_loss: 0.6502 - learning_rate: 6.2500e-05\n",
      "Epoch 96/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8627 - loss: 0.4378 - val_accuracy: 0.8482 - val_loss: 0.6508 - learning_rate: 6.2500e-05\n",
      "Epoch 97/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8505 - loss: 0.4480 - val_accuracy: 0.8409 - val_loss: 0.6539 - learning_rate: 6.2500e-05\n",
      "Epoch 98/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8646 - loss: 0.4402 - val_accuracy: 0.8449 - val_loss: 0.6529 - learning_rate: 6.2500e-05\n",
      "Epoch 99/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8489 - loss: 0.4455 - val_accuracy: 0.8420 - val_loss: 0.6557 - learning_rate: 3.1250e-05\n",
      "Epoch 100/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8637 - loss: 0.4310 - val_accuracy: 0.8465 - val_loss: 0.6552 - learning_rate: 3.1250e-05\n",
      "Epoch 101/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8626 - loss: 0.4332 - val_accuracy: 0.8432 - val_loss: 0.6583 - learning_rate: 3.1250e-05\n",
      "Epoch 102/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8668 - loss: 0.4255 - val_accuracy: 0.8454 - val_loss: 0.6425 - learning_rate: 1.5625e-05\n",
      "Epoch 103/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8657 - loss: 0.4241 - val_accuracy: 0.8516 - val_loss: 0.6386 - learning_rate: 1.5625e-05\n",
      "Epoch 104/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8653 - loss: 0.4203 - val_accuracy: 0.8488 - val_loss: 0.6416 - learning_rate: 1.5625e-05\n",
      "Epoch 105/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8771 - loss: 0.4155 - val_accuracy: 0.8471 - val_loss: 0.6407 - learning_rate: 1.5625e-05\n",
      "Epoch 106/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8673 - loss: 0.4230 - val_accuracy: 0.8499 - val_loss: 0.6359 - learning_rate: 1.5625e-05\n",
      "Epoch 107/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8717 - loss: 0.4106 - val_accuracy: 0.8499 - val_loss: 0.6335 - learning_rate: 1.5625e-05\n",
      "Epoch 108/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8693 - loss: 0.4300 - val_accuracy: 0.8488 - val_loss: 0.6382 - learning_rate: 1.5625e-05\n",
      "Epoch 109/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8790 - loss: 0.4063 - val_accuracy: 0.8477 - val_loss: 0.6369 - learning_rate: 1.5625e-05\n",
      "Epoch 110/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8629 - loss: 0.4262 - val_accuracy: 0.8494 - val_loss: 0.6333 - learning_rate: 1.5625e-05\n",
      "Epoch 111/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8809 - loss: 0.4016 - val_accuracy: 0.8471 - val_loss: 0.6359 - learning_rate: 1.5625e-05\n",
      "Epoch 112/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.8744 - loss: 0.4160 - val_accuracy: 0.8465 - val_loss: 0.6328 - learning_rate: 1.5625e-05\n",
      "Epoch 113/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.8758 - loss: 0.4056 - val_accuracy: 0.8499 - val_loss: 0.6351 - learning_rate: 1.5625e-05\n",
      "Epoch 114/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.8812 - loss: 0.4034 - val_accuracy: 0.8527 - val_loss: 0.6288 - learning_rate: 1.5625e-05\n",
      "Epoch 115/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8693 - loss: 0.4103 - val_accuracy: 0.8510 - val_loss: 0.6367 - learning_rate: 1.5625e-05\n",
      "Epoch 116/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8783 - loss: 0.4056 - val_accuracy: 0.8471 - val_loss: 0.6347 - learning_rate: 1.5625e-05\n",
      "Epoch 117/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8712 - loss: 0.4061 - val_accuracy: 0.8572 - val_loss: 0.6265 - learning_rate: 1.5625e-05\n",
      "Epoch 118/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8707 - loss: 0.4153 - val_accuracy: 0.8572 - val_loss: 0.6200 - learning_rate: 1.5625e-05\n",
      "Epoch 119/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8765 - loss: 0.3981 - val_accuracy: 0.8544 - val_loss: 0.6242 - learning_rate: 1.5625e-05\n",
      "Epoch 120/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8880 - loss: 0.3929 - val_accuracy: 0.8505 - val_loss: 0.6266 - learning_rate: 1.5625e-05\n",
      "Epoch 121/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8832 - loss: 0.3866 - val_accuracy: 0.8544 - val_loss: 0.6225 - learning_rate: 1.5625e-05\n",
      "Epoch 122/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8742 - loss: 0.3988 - val_accuracy: 0.8516 - val_loss: 0.6243 - learning_rate: 7.8125e-06\n",
      "Epoch 123/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8757 - loss: 0.3980 - val_accuracy: 0.8510 - val_loss: 0.6257 - learning_rate: 7.8125e-06\n",
      "Epoch 124/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.8752 - loss: 0.4012 - val_accuracy: 0.8527 - val_loss: 0.6221 - learning_rate: 7.8125e-06\n",
      "Epoch 125/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.8709 - loss: 0.4136 - val_accuracy: 0.8510 - val_loss: 0.6235 - learning_rate: 3.9063e-06\n",
      "Epoch 126/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8853 - loss: 0.3875 - val_accuracy: 0.8527 - val_loss: 0.6228 - learning_rate: 3.9063e-06\n",
      "Epoch 127/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8810 - loss: 0.3908 - val_accuracy: 0.8522 - val_loss: 0.6217 - learning_rate: 3.9063e-06\n",
      "Epoch 128/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8826 - loss: 0.3956 - val_accuracy: 0.8522 - val_loss: 0.6241 - learning_rate: 1.9531e-06\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "\n",
      "🧾 Fold 4 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.89      0.96      0.93       422\n",
      "     Jogging       0.88      0.72      0.79       325\n",
      "     Sitting       0.90      0.92      0.91        61\n",
      "    Standing       0.81      0.61      0.70        49\n",
      "    Upstairs       0.86      0.98      0.91       506\n",
      "     Walking       0.80      0.73      0.77       416\n",
      "\n",
      "    accuracy                           0.86      1779\n",
      "   macro avg       0.86      0.82      0.83      1779\n",
      "weighted avg       0.86      0.86      0.85      1779\n",
      "\n",
      "\n",
      "📚 Training Fold 5\n",
      "Epoch 1/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.2986 - loss: 5.1595 - val_accuracy: 0.2693 - val_loss: 3.1080 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.3835 - loss: 2.4908 - val_accuracy: 0.2934 - val_loss: 2.1511 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.4186 - loss: 1.7165 - val_accuracy: 0.4193 - val_loss: 1.7300 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.4428 - loss: 1.4645 - val_accuracy: 0.4396 - val_loss: 1.5418 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.4268 - loss: 1.3718 - val_accuracy: 0.3946 - val_loss: 1.5333 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.4644 - loss: 1.3025 - val_accuracy: 0.4609 - val_loss: 1.4120 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.4632 - loss: 1.3088 - val_accuracy: 0.4429 - val_loss: 1.4012 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.4592 - loss: 1.1876 - val_accuracy: 0.4463 - val_loss: 1.4455 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.4427 - loss: 1.2875 - val_accuracy: 0.4536 - val_loss: 1.4339 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.4562 - loss: 1.2166 - val_accuracy: 0.4666 - val_loss: 1.3739 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.4709 - loss: 1.1966 - val_accuracy: 0.4547 - val_loss: 1.3655 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.4793 - loss: 1.1503 - val_accuracy: 0.4761 - val_loss: 1.3502 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.4757 - loss: 1.2026 - val_accuracy: 0.4744 - val_loss: 1.3406 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.4868 - loss: 1.1518 - val_accuracy: 0.4845 - val_loss: 1.3460 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.4752 - loss: 1.1558 - val_accuracy: 0.4688 - val_loss: 1.3541 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.5019 - loss: 1.1014 - val_accuracy: 0.4885 - val_loss: 1.3302 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.4966 - loss: 1.1122 - val_accuracy: 0.4626 - val_loss: 1.4284 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.4795 - loss: 1.1667 - val_accuracy: 0.4935 - val_loss: 1.3317 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - accuracy: 0.5027 - loss: 1.1396 - val_accuracy: 0.4800 - val_loss: 1.3556 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.5147 - loss: 1.1139 - val_accuracy: 0.5093 - val_loss: 1.2826 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.5292 - loss: 1.0120 - val_accuracy: 0.5053 - val_loss: 1.2577 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.5295 - loss: 1.0631 - val_accuracy: 0.5087 - val_loss: 1.2681 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.5549 - loss: 0.9540 - val_accuracy: 0.5250 - val_loss: 1.2239 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.5443 - loss: 0.9817 - val_accuracy: 0.5351 - val_loss: 1.2521 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.5685 - loss: 0.9771 - val_accuracy: 0.5379 - val_loss: 1.2112 - learning_rate: 5.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.5661 - loss: 0.9421 - val_accuracy: 0.5261 - val_loss: 1.2317 - learning_rate: 5.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.5674 - loss: 0.9270 - val_accuracy: 0.5402 - val_loss: 1.2286 - learning_rate: 5.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.5617 - loss: 1.0054 - val_accuracy: 0.5295 - val_loss: 1.2422 - learning_rate: 5.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5713 - loss: 0.9401 - val_accuracy: 0.5509 - val_loss: 1.1965 - learning_rate: 2.5000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.6084 - loss: 0.8710 - val_accuracy: 0.5717 - val_loss: 1.1804 - learning_rate: 2.5000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.6068 - loss: 0.8578 - val_accuracy: 0.5750 - val_loss: 1.1636 - learning_rate: 2.5000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.6234 - loss: 0.8392 - val_accuracy: 0.5829 - val_loss: 1.1450 - learning_rate: 2.5000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - accuracy: 0.6257 - loss: 0.8470 - val_accuracy: 0.5857 - val_loss: 1.1345 - learning_rate: 2.5000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.6398 - loss: 0.8280 - val_accuracy: 0.5818 - val_loss: 1.1456 - learning_rate: 2.5000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.6299 - loss: 0.8251 - val_accuracy: 0.5790 - val_loss: 1.1442 - learning_rate: 2.5000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.6418 - loss: 0.7878 - val_accuracy: 0.6105 - val_loss: 1.1093 - learning_rate: 2.5000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6426 - loss: 0.8196 - val_accuracy: 0.6189 - val_loss: 1.0845 - learning_rate: 2.5000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.6625 - loss: 0.7720 - val_accuracy: 0.6144 - val_loss: 1.1003 - learning_rate: 2.5000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - accuracy: 0.6650 - loss: 0.7790 - val_accuracy: 0.6408 - val_loss: 1.0488 - learning_rate: 2.5000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.6724 - loss: 0.7845 - val_accuracy: 0.6526 - val_loss: 1.0490 - learning_rate: 2.5000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.6792 - loss: 0.7483 - val_accuracy: 0.6369 - val_loss: 1.0560 - learning_rate: 2.5000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6887 - loss: 0.7596 - val_accuracy: 0.6537 - val_loss: 1.0488 - learning_rate: 2.5000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.7087 - loss: 0.7270 - val_accuracy: 0.6633 - val_loss: 1.0095 - learning_rate: 1.2500e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.7225 - loss: 0.6983 - val_accuracy: 0.6785 - val_loss: 0.9944 - learning_rate: 1.2500e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.7230 - loss: 0.6878 - val_accuracy: 0.6892 - val_loss: 0.9717 - learning_rate: 1.2500e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.7326 - loss: 0.6794 - val_accuracy: 0.6970 - val_loss: 0.9575 - learning_rate: 1.2500e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.7490 - loss: 0.6542 - val_accuracy: 0.7161 - val_loss: 0.9413 - learning_rate: 1.2500e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7579 - loss: 0.6378 - val_accuracy: 0.7234 - val_loss: 0.9239 - learning_rate: 1.2500e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7467 - loss: 0.6410 - val_accuracy: 0.7324 - val_loss: 0.9227 - learning_rate: 1.2500e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7528 - loss: 0.6360 - val_accuracy: 0.7279 - val_loss: 0.9169 - learning_rate: 1.2500e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.7674 - loss: 0.6089 - val_accuracy: 0.7336 - val_loss: 0.8904 - learning_rate: 1.2500e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.7598 - loss: 0.6315 - val_accuracy: 0.7369 - val_loss: 0.8865 - learning_rate: 1.2500e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.7561 - loss: 0.6522 - val_accuracy: 0.7403 - val_loss: 0.8706 - learning_rate: 1.2500e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.7749 - loss: 0.6015 - val_accuracy: 0.7639 - val_loss: 0.8523 - learning_rate: 1.2500e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7763 - loss: 0.6015 - val_accuracy: 0.7645 - val_loss: 0.8501 - learning_rate: 1.2500e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7931 - loss: 0.5804 - val_accuracy: 0.7746 - val_loss: 0.8210 - learning_rate: 1.2500e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7862 - loss: 0.5917 - val_accuracy: 0.7667 - val_loss: 0.8311 - learning_rate: 1.2500e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7821 - loss: 0.6057 - val_accuracy: 0.7780 - val_loss: 0.8176 - learning_rate: 1.2500e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7831 - loss: 0.6041 - val_accuracy: 0.7830 - val_loss: 0.8014 - learning_rate: 1.2500e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8063 - loss: 0.5534 - val_accuracy: 0.7768 - val_loss: 0.7917 - learning_rate: 1.2500e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7885 - loss: 0.5888 - val_accuracy: 0.7678 - val_loss: 0.8255 - learning_rate: 1.2500e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8047 - loss: 0.5583 - val_accuracy: 0.7903 - val_loss: 0.7892 - learning_rate: 1.2500e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8121 - loss: 0.5489 - val_accuracy: 0.7830 - val_loss: 0.8019 - learning_rate: 1.2500e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8114 - loss: 0.5550 - val_accuracy: 0.7802 - val_loss: 0.7925 - learning_rate: 1.2500e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8101 - loss: 0.5230 - val_accuracy: 0.7948 - val_loss: 0.7620 - learning_rate: 1.2500e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8111 - loss: 0.5415 - val_accuracy: 0.7965 - val_loss: 0.7719 - learning_rate: 1.2500e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8058 - loss: 0.5490 - val_accuracy: 0.8055 - val_loss: 0.7585 - learning_rate: 1.2500e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8244 - loss: 0.5208 - val_accuracy: 0.8061 - val_loss: 0.7517 - learning_rate: 1.2500e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8257 - loss: 0.5225 - val_accuracy: 0.7982 - val_loss: 0.7471 - learning_rate: 1.2500e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8258 - loss: 0.5283 - val_accuracy: 0.8173 - val_loss: 0.7230 - learning_rate: 1.2500e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8169 - loss: 0.5401 - val_accuracy: 0.8123 - val_loss: 0.7295 - learning_rate: 1.2500e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8267 - loss: 0.5180 - val_accuracy: 0.8055 - val_loss: 0.7384 - learning_rate: 1.2500e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8226 - loss: 0.5180 - val_accuracy: 0.8168 - val_loss: 0.7202 - learning_rate: 1.2500e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8261 - loss: 0.5249 - val_accuracy: 0.8224 - val_loss: 0.7053 - learning_rate: 1.2500e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8252 - loss: 0.5256 - val_accuracy: 0.8083 - val_loss: 0.7260 - learning_rate: 1.2500e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8349 - loss: 0.5045 - val_accuracy: 0.8235 - val_loss: 0.7103 - learning_rate: 1.2500e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8399 - loss: 0.4859 - val_accuracy: 0.8100 - val_loss: 0.7160 - learning_rate: 1.2500e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8439 - loss: 0.4835 - val_accuracy: 0.8241 - val_loss: 0.7003 - learning_rate: 6.2500e-05\n",
      "Epoch 79/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8536 - loss: 0.4763 - val_accuracy: 0.8224 - val_loss: 0.6976 - learning_rate: 6.2500e-05\n",
      "Epoch 80/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8506 - loss: 0.4751 - val_accuracy: 0.8257 - val_loss: 0.6920 - learning_rate: 6.2500e-05\n",
      "Epoch 81/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8586 - loss: 0.4599 - val_accuracy: 0.8308 - val_loss: 0.6821 - learning_rate: 6.2500e-05\n",
      "Epoch 82/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8633 - loss: 0.4486 - val_accuracy: 0.8302 - val_loss: 0.6911 - learning_rate: 6.2500e-05\n",
      "Epoch 83/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8574 - loss: 0.4667 - val_accuracy: 0.8280 - val_loss: 0.6805 - learning_rate: 6.2500e-05\n",
      "Epoch 84/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8600 - loss: 0.4577 - val_accuracy: 0.8224 - val_loss: 0.6833 - learning_rate: 6.2500e-05\n",
      "Epoch 85/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8433 - loss: 0.4648 - val_accuracy: 0.8319 - val_loss: 0.6699 - learning_rate: 6.2500e-05\n",
      "Epoch 86/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8611 - loss: 0.4459 - val_accuracy: 0.8291 - val_loss: 0.6697 - learning_rate: 6.2500e-05\n",
      "Epoch 87/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8627 - loss: 0.4468 - val_accuracy: 0.8342 - val_loss: 0.6695 - learning_rate: 6.2500e-05\n",
      "Epoch 88/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8627 - loss: 0.4442 - val_accuracy: 0.8319 - val_loss: 0.6776 - learning_rate: 6.2500e-05\n",
      "Epoch 89/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8588 - loss: 0.4671 - val_accuracy: 0.8302 - val_loss: 0.6617 - learning_rate: 6.2500e-05\n",
      "Epoch 90/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8686 - loss: 0.4311 - val_accuracy: 0.8336 - val_loss: 0.6691 - learning_rate: 6.2500e-05\n",
      "Epoch 91/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8601 - loss: 0.4428 - val_accuracy: 0.8308 - val_loss: 0.6649 - learning_rate: 6.2500e-05\n",
      "Epoch 92/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8551 - loss: 0.4596 - val_accuracy: 0.8314 - val_loss: 0.6699 - learning_rate: 6.2500e-05\n",
      "Epoch 93/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8632 - loss: 0.4529 - val_accuracy: 0.8325 - val_loss: 0.6697 - learning_rate: 3.1250e-05\n",
      "Epoch 94/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8630 - loss: 0.4377 - val_accuracy: 0.8263 - val_loss: 0.6665 - learning_rate: 3.1250e-05\n",
      "Epoch 95/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8820 - loss: 0.4167 - val_accuracy: 0.8392 - val_loss: 0.6598 - learning_rate: 3.1250e-05\n",
      "Epoch 96/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8701 - loss: 0.4179 - val_accuracy: 0.8381 - val_loss: 0.6524 - learning_rate: 3.1250e-05\n",
      "Epoch 97/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8830 - loss: 0.4205 - val_accuracy: 0.8392 - val_loss: 0.6508 - learning_rate: 3.1250e-05\n",
      "Epoch 98/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8667 - loss: 0.4295 - val_accuracy: 0.8460 - val_loss: 0.6530 - learning_rate: 3.1250e-05\n",
      "Epoch 99/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8817 - loss: 0.4092 - val_accuracy: 0.8443 - val_loss: 0.6471 - learning_rate: 3.1250e-05\n",
      "Epoch 100/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8708 - loss: 0.4211 - val_accuracy: 0.8443 - val_loss: 0.6433 - learning_rate: 3.1250e-05\n",
      "Epoch 101/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8835 - loss: 0.4045 - val_accuracy: 0.8409 - val_loss: 0.6514 - learning_rate: 3.1250e-05\n",
      "Epoch 102/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8806 - loss: 0.4137 - val_accuracy: 0.8426 - val_loss: 0.6437 - learning_rate: 3.1250e-05\n",
      "Epoch 103/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8777 - loss: 0.4043 - val_accuracy: 0.8364 - val_loss: 0.6468 - learning_rate: 3.1250e-05\n",
      "Epoch 104/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8811 - loss: 0.4071 - val_accuracy: 0.8432 - val_loss: 0.6425 - learning_rate: 1.5625e-05\n",
      "Epoch 105/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8785 - loss: 0.4051 - val_accuracy: 0.8471 - val_loss: 0.6389 - learning_rate: 1.5625e-05\n",
      "Epoch 106/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8898 - loss: 0.4106 - val_accuracy: 0.8415 - val_loss: 0.6435 - learning_rate: 1.5625e-05\n",
      "Epoch 107/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8744 - loss: 0.4238 - val_accuracy: 0.8432 - val_loss: 0.6440 - learning_rate: 1.5625e-05\n",
      "Epoch 108/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8845 - loss: 0.3995 - val_accuracy: 0.8426 - val_loss: 0.6385 - learning_rate: 1.5625e-05\n",
      "Epoch 109/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8780 - loss: 0.4020 - val_accuracy: 0.8460 - val_loss: 0.6350 - learning_rate: 1.5625e-05\n",
      "Epoch 110/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8781 - loss: 0.3975 - val_accuracy: 0.8381 - val_loss: 0.6408 - learning_rate: 1.5625e-05\n",
      "Epoch 111/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8813 - loss: 0.4084 - val_accuracy: 0.8432 - val_loss: 0.6393 - learning_rate: 1.5625e-05\n",
      "Epoch 112/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8905 - loss: 0.4049 - val_accuracy: 0.8420 - val_loss: 0.6387 - learning_rate: 1.5625e-05\n",
      "Epoch 113/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8727 - loss: 0.4122 - val_accuracy: 0.8426 - val_loss: 0.6382 - learning_rate: 7.8125e-06\n",
      "Epoch 114/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8860 - loss: 0.3830 - val_accuracy: 0.8482 - val_loss: 0.6352 - learning_rate: 7.8125e-06\n",
      "Epoch 115/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8796 - loss: 0.3974 - val_accuracy: 0.8460 - val_loss: 0.6352 - learning_rate: 7.8125e-06\n",
      "Epoch 116/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8856 - loss: 0.3936 - val_accuracy: 0.8454 - val_loss: 0.6355 - learning_rate: 3.9063e-06\n",
      "Epoch 117/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8886 - loss: 0.3858 - val_accuracy: 0.8454 - val_loss: 0.6343 - learning_rate: 3.9063e-06\n",
      "Epoch 118/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8826 - loss: 0.4101 - val_accuracy: 0.8465 - val_loss: 0.6343 - learning_rate: 3.9063e-06\n",
      "Epoch 119/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8949 - loss: 0.3831 - val_accuracy: 0.8477 - val_loss: 0.6328 - learning_rate: 3.9063e-06\n",
      "Epoch 120/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8862 - loss: 0.3888 - val_accuracy: 0.8494 - val_loss: 0.6331 - learning_rate: 3.9063e-06\n",
      "Epoch 121/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8886 - loss: 0.3902 - val_accuracy: 0.8488 - val_loss: 0.6326 - learning_rate: 3.9063e-06\n",
      "Epoch 122/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8755 - loss: 0.4128 - val_accuracy: 0.8488 - val_loss: 0.6321 - learning_rate: 3.9063e-06\n",
      "Epoch 123/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8843 - loss: 0.3966 - val_accuracy: 0.8460 - val_loss: 0.6326 - learning_rate: 3.9063e-06\n",
      "Epoch 124/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8818 - loss: 0.3989 - val_accuracy: 0.8465 - val_loss: 0.6318 - learning_rate: 3.9063e-06\n",
      "Epoch 125/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8907 - loss: 0.3887 - val_accuracy: 0.8471 - val_loss: 0.6316 - learning_rate: 3.9063e-06\n",
      "Epoch 126/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8922 - loss: 0.3823 - val_accuracy: 0.8454 - val_loss: 0.6308 - learning_rate: 3.9063e-06\n",
      "Epoch 127/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8952 - loss: 0.3840 - val_accuracy: 0.8488 - val_loss: 0.6282 - learning_rate: 3.9063e-06\n",
      "Epoch 128/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8855 - loss: 0.3906 - val_accuracy: 0.8482 - val_loss: 0.6296 - learning_rate: 3.9063e-06\n",
      "Epoch 129/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8886 - loss: 0.3922 - val_accuracy: 0.8488 - val_loss: 0.6291 - learning_rate: 3.9063e-06\n",
      "Epoch 130/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8930 - loss: 0.3950 - val_accuracy: 0.8488 - val_loss: 0.6291 - learning_rate: 3.9063e-06\n",
      "Epoch 131/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8907 - loss: 0.3920 - val_accuracy: 0.8510 - val_loss: 0.6277 - learning_rate: 1.9531e-06\n",
      "Epoch 132/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8884 - loss: 0.4001 - val_accuracy: 0.8505 - val_loss: 0.6283 - learning_rate: 1.9531e-06\n",
      "Epoch 133/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8743 - loss: 0.3940 - val_accuracy: 0.8494 - val_loss: 0.6288 - learning_rate: 1.9531e-06\n",
      "Epoch 134/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8910 - loss: 0.3965 - val_accuracy: 0.8477 - val_loss: 0.6286 - learning_rate: 1.9531e-06\n",
      "Epoch 135/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8802 - loss: 0.4023 - val_accuracy: 0.8477 - val_loss: 0.6285 - learning_rate: 1.0000e-06\n",
      "Epoch 136/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8836 - loss: 0.4047 - val_accuracy: 0.8488 - val_loss: 0.6292 - learning_rate: 1.0000e-06\n",
      "Epoch 137/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8854 - loss: 0.3899 - val_accuracy: 0.8494 - val_loss: 0.6278 - learning_rate: 1.0000e-06\n",
      "Epoch 138/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8875 - loss: 0.3946 - val_accuracy: 0.8482 - val_loss: 0.6282 - learning_rate: 1.0000e-06\n",
      "Epoch 139/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8874 - loss: 0.3866 - val_accuracy: 0.8477 - val_loss: 0.6280 - learning_rate: 1.0000e-06\n",
      "Epoch 140/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8899 - loss: 0.3860 - val_accuracy: 0.8477 - val_loss: 0.6285 - learning_rate: 1.0000e-06\n",
      "Epoch 141/150\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8915 - loss: 0.3784 - val_accuracy: 0.8482 - val_loss: 0.6290 - learning_rate: 1.0000e-06\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\n",
      "🧾 Fold 5 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.87      0.96      0.92       423\n",
      "     Jogging       0.83      0.73      0.78       325\n",
      "     Sitting       0.92      0.90      0.91        61\n",
      "    Standing       0.93      0.76      0.83        49\n",
      "    Upstairs       0.90      0.96      0.93       505\n",
      "     Walking       0.76      0.71      0.73       416\n",
      "\n",
      "    accuracy                           0.85      1779\n",
      "   macro avg       0.87      0.84      0.85      1779\n",
      "weighted avg       0.85      0.85      0.85      1779\n",
      "\n",
      "\n",
      "✅ Average Macro F1-Score across 5 folds: 0.8414 ± 0.0151\n"
     ]
    }
   ],
   "source": [
    "# === REPLACE your old training script with this one ===\n",
    "\n",
    "# Build CNN-LSTM with residual connections\n",
    "def build_cnn_lstm_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN Block 1\n",
    "    x = Conv1D(64, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Residual Connection\n",
    "    conv1 = Conv1D(64, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    x = Add()([x, conv1])\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # CNN Block 2\n",
    "    x = Conv1D(128, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # LSTM Layer\n",
    "    x = LSTM(128, return_sequences=False, kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Dense Layers\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "f1_scores = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X_augmented, y_augmented):\n",
    "    print(f\"\\n📚 Training Fold {fold}\")\n",
    "    X_train, X_val = X_augmented[train_idx], X_augmented[val_idx]\n",
    "    y_train, y_val = y_augmented[train_idx], y_augmented[val_idx]\n",
    "    \n",
    "    # Optional: light data augmentation on training data (e.g., jittering)\n",
    "    # X_train = add_jitter(X_train, sigma=0.02)\n",
    "\n",
    "    model = build_cnn_lstm_model(input_shape=(10, 3), num_classes=len(np.unique(y_augmented)))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=150,\n",
    "        batch_size=64,\n",
    "        class_weight=class_weight_dict_aug,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    print(f\"\\n🧾 Fold {fold} Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred_classes, target_names=label_encoder.classes_))\n",
    "    \n",
    "    # Store macro F1-score\n",
    "    report = classification_report(y_val, y_pred_classes, output_dict=True)\n",
    "    f1_scores.append(report['macro avg']['f1-score'])\n",
    "    fold += 1\n",
    "\n",
    "# Final macro F1 score across folds\n",
    "print(f\"\\n✅ Average Macro F1-Score across {skf.n_splits} folds: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dec322",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
