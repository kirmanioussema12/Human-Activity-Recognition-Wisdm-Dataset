{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87369c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization, Add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: simple jittering function for augmentation\n",
    "def add_jitter(X, sigma=0.01):\n",
    "    noise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n",
    "    return X + noise\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\HAR-WISDM\\Data_WISDM\\WISDM_cleaned.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Encode class labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape data for CNN-LSTM: assuming 30 features = (10 time steps × 3 features)\n",
    "X_reshaped = X_scaled.reshape(-1, 10, 3)\n",
    "y_reshaped = y_encoded.reshape(-1)\n",
    "\n",
    "# === 1. Augment Downstairs, Upstairs, Standing using factor ===\n",
    "def augment_minority_classes(X, y, classes_to_augment, augment_func, augment_factor=2):\n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "\n",
    "    for cls in classes_to_augment:\n",
    "        X_cls = X[y == cls]\n",
    "        for _ in range(augment_factor):\n",
    "            X_augmented.append(augment_func(X_cls))\n",
    "            y_augmented.append(np.full(len(X_cls), cls))\n",
    "\n",
    "    X_aug = np.concatenate(X_augmented, axis=0)\n",
    "    y_aug = np.concatenate(y_augmented, axis=0)\n",
    "\n",
    "    X_new = np.concatenate([X, X_aug], axis=0)\n",
    "    y_new = np.concatenate([y, y_aug], axis=0)\n",
    "\n",
    "    return X_new, y_new\n",
    "\n",
    "classes_to_augment = []\n",
    "for class_name in ['Downstairs', 'Upstairs', 'Standing']:\n",
    "    cls_idx = label_encoder.transform([class_name])[0]\n",
    "    classes_to_augment.append(cls_idx)\n",
    "\n",
    "X_temp, y_temp = augment_minority_classes(X_reshaped, y_reshaped, classes_to_augment, add_jitter, augment_factor=3)\n",
    "\n",
    "# === 2. Augment Jogging (400) and Walking (200) specifically ===\n",
    "def augment_specific_classes(X, y, class_sample_map, augment_func):\n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "\n",
    "    for cls, n_samples in class_sample_map.items():\n",
    "        X_cls = X[y == cls]\n",
    "        sampled_indices = np.random.choice(len(X_cls), size=n_samples, replace=True)\n",
    "        X_sampled = X_cls[sampled_indices]\n",
    "        X_aug = augment_func(X_sampled)\n",
    "        X_augmented.append(X_aug)\n",
    "        y_augmented.append(np.full(n_samples, cls))\n",
    "\n",
    "    X_new = np.concatenate([X] + X_augmented, axis=0)\n",
    "    y_new = np.concatenate([y] + y_augmented, axis=0)\n",
    "\n",
    "    return X_new, y_new\n",
    "\n",
    "# Define how many samples to add per class\n",
    "class_sample_map = {}\n",
    "for class_name, n_samples in [('Jogging', 1200), ('Walking',1300),('Sitting', 2300), ('Standing',1900), ('Downstairs', 500), ('Upstairs',400)]:\n",
    "    cls_idx = label_encoder.transform([class_name])[0]\n",
    "    class_sample_map[cls_idx] = n_samples\n",
    "\n",
    "# Apply the specific class augmentation\n",
    "X_augmented, y_augmented = augment_specific_classes(X_temp, y_temp, class_sample_map, add_jitter)\n",
    "\n",
    "# === Compute class weights ===\n",
    "class_weights_aug = compute_class_weight('balanced', classes=np.unique(y_augmented), y=y_augmented)\n",
    "class_weight_dict_aug = dict(enumerate(class_weights_aug))\n",
    "\n",
    "# === Visualize final class distribution ===\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x=label_encoder.inverse_transform(y_augmented))\n",
    "plt.title('Final Augmented Class Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# You can now use: X_augmented, y_augmented, class_weight_dict_aug in training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40c1a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Training Fold 1\n",
      "Epoch 1/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.4288 - loss: 3.8531 - val_accuracy: 0.4806 - val_loss: 1.6459 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.5407 - loss: 1.3204 - val_accuracy: 0.5789 - val_loss: 1.1467 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.5747 - loss: 1.1319 - val_accuracy: 0.5757 - val_loss: 1.1069 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.5902 - loss: 1.0936 - val_accuracy: 0.6111 - val_loss: 1.0550 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6114 - loss: 1.0494 - val_accuracy: 0.6386 - val_loss: 1.0080 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6115 - loss: 1.0437 - val_accuracy: 0.5960 - val_loss: 1.0947 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6185 - loss: 1.0352 - val_accuracy: 0.6383 - val_loss: 1.0115 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6278 - loss: 1.0372 - val_accuracy: 0.6557 - val_loss: 0.9946 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6334 - loss: 1.0340 - val_accuracy: 0.6534 - val_loss: 1.0044 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6376 - loss: 1.0107 - val_accuracy: 0.6357 - val_loss: 0.9933 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6430 - loss: 0.9994 - val_accuracy: 0.6685 - val_loss: 0.9851 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6573 - loss: 0.9991 - val_accuracy: 0.6731 - val_loss: 0.9750 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6573 - loss: 0.9778 - val_accuracy: 0.6621 - val_loss: 0.9849 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6600 - loss: 0.9889 - val_accuracy: 0.6668 - val_loss: 0.9771 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.6769 - loss: 0.9662 - val_accuracy: 0.6987 - val_loss: 0.9169 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6727 - loss: 0.9550 - val_accuracy: 0.6746 - val_loss: 0.9885 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6659 - loss: 0.9770 - val_accuracy: 0.6911 - val_loss: 0.9281 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6769 - loss: 0.9593 - val_accuracy: 0.6963 - val_loss: 0.9439 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6941 - loss: 0.9094 - val_accuracy: 0.6992 - val_loss: 0.8535 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7073 - loss: 0.8453 - val_accuracy: 0.7291 - val_loss: 0.8067 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7239 - loss: 0.8039 - val_accuracy: 0.7401 - val_loss: 0.8050 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7270 - loss: 0.8001 - val_accuracy: 0.7352 - val_loss: 0.7964 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7282 - loss: 0.8067 - val_accuracy: 0.7436 - val_loss: 0.7811 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7240 - loss: 0.7942 - val_accuracy: 0.7465 - val_loss: 0.7685 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7337 - loss: 0.7932 - val_accuracy: 0.7387 - val_loss: 0.7947 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7350 - loss: 0.7795 - val_accuracy: 0.7610 - val_loss: 0.7672 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7485 - loss: 0.7690 - val_accuracy: 0.7767 - val_loss: 0.7352 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7663 - loss: 0.7546 - val_accuracy: 0.7810 - val_loss: 0.7287 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7545 - loss: 0.7702 - val_accuracy: 0.7703 - val_loss: 0.7552 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7498 - loss: 0.7704 - val_accuracy: 0.7889 - val_loss: 0.7110 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7550 - loss: 0.7625 - val_accuracy: 0.7906 - val_loss: 0.7141 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7565 - loss: 0.7672 - val_accuracy: 0.7787 - val_loss: 0.7242 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7685 - loss: 0.7432 - val_accuracy: 0.8002 - val_loss: 0.6988 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7664 - loss: 0.7435 - val_accuracy: 0.8071 - val_loss: 0.6948 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7726 - loss: 0.7418 - val_accuracy: 0.8031 - val_loss: 0.7007 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7767 - loss: 0.7474 - val_accuracy: 0.8002 - val_loss: 0.6946 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7704 - loss: 0.7483 - val_accuracy: 0.8097 - val_loss: 0.6908 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7796 - loss: 0.7383 - val_accuracy: 0.8109 - val_loss: 0.6916 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7838 - loss: 0.7285 - val_accuracy: 0.8126 - val_loss: 0.6877 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7859 - loss: 0.7086 - val_accuracy: 0.8022 - val_loss: 0.6963 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7729 - loss: 0.7370 - val_accuracy: 0.8179 - val_loss: 0.6844 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7962 - loss: 0.7065 - val_accuracy: 0.8248 - val_loss: 0.6621 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7847 - loss: 0.7350 - val_accuracy: 0.8373 - val_loss: 0.6583 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7925 - loss: 0.7192 - val_accuracy: 0.8274 - val_loss: 0.6572 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7947 - loss: 0.7027 - val_accuracy: 0.8286 - val_loss: 0.6578 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7948 - loss: 0.7153 - val_accuracy: 0.8390 - val_loss: 0.6327 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8006 - loss: 0.7071 - val_accuracy: 0.8405 - val_loss: 0.6475 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7967 - loss: 0.7034 - val_accuracy: 0.8492 - val_loss: 0.6233 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8053 - loss: 0.6936 - val_accuracy: 0.8457 - val_loss: 0.6386 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8101 - loss: 0.6891 - val_accuracy: 0.8486 - val_loss: 0.6311 - learning_rate: 5.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8056 - loss: 0.6983 - val_accuracy: 0.8486 - val_loss: 0.6253 - learning_rate: 5.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8235 - loss: 0.6534 - val_accuracy: 0.8788 - val_loss: 0.5488 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8458 - loss: 0.6042 - val_accuracy: 0.8846 - val_loss: 0.5297 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8456 - loss: 0.5896 - val_accuracy: 0.8849 - val_loss: 0.5283 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8360 - loss: 0.6018 - val_accuracy: 0.8921 - val_loss: 0.5048 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8476 - loss: 0.5852 - val_accuracy: 0.8991 - val_loss: 0.5011 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8524 - loss: 0.5621 - val_accuracy: 0.8939 - val_loss: 0.4948 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8477 - loss: 0.5676 - val_accuracy: 0.8979 - val_loss: 0.4830 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8537 - loss: 0.5624 - val_accuracy: 0.9026 - val_loss: 0.4869 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.8518 - loss: 0.5615 - val_accuracy: 0.9031 - val_loss: 0.4765 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.8593 - loss: 0.5438 - val_accuracy: 0.8854 - val_loss: 0.5038 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.8573 - loss: 0.5470 - val_accuracy: 0.9060 - val_loss: 0.4572 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.8617 - loss: 0.5291 - val_accuracy: 0.9086 - val_loss: 0.4542 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.8543 - loss: 0.5402 - val_accuracy: 0.9095 - val_loss: 0.4503 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8637 - loss: 0.5287 - val_accuracy: 0.8982 - val_loss: 0.4760 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8564 - loss: 0.5490 - val_accuracy: 0.9144 - val_loss: 0.4466 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8601 - loss: 0.5336 - val_accuracy: 0.9072 - val_loss: 0.4439 - learning_rate: 2.5000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8564 - loss: 0.5398 - val_accuracy: 0.9156 - val_loss: 0.4394 - learning_rate: 2.5000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8664 - loss: 0.5221 - val_accuracy: 0.9159 - val_loss: 0.4393 - learning_rate: 2.5000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8628 - loss: 0.5221 - val_accuracy: 0.9081 - val_loss: 0.4542 - learning_rate: 2.5000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8629 - loss: 0.5236 - val_accuracy: 0.9075 - val_loss: 0.4475 - learning_rate: 2.5000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8753 - loss: 0.5028 - val_accuracy: 0.9188 - val_loss: 0.4157 - learning_rate: 1.2500e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8760 - loss: 0.4826 - val_accuracy: 0.9159 - val_loss: 0.4189 - learning_rate: 1.2500e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8882 - loss: 0.4622 - val_accuracy: 0.9310 - val_loss: 0.3859 - learning_rate: 1.2500e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8936 - loss: 0.4547 - val_accuracy: 0.9275 - val_loss: 0.3855 - learning_rate: 1.2500e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.8946 - loss: 0.4399 - val_accuracy: 0.9333 - val_loss: 0.3839 - learning_rate: 1.2500e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8870 - loss: 0.4593 - val_accuracy: 0.9292 - val_loss: 0.3769 - learning_rate: 1.2500e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8944 - loss: 0.4376 - val_accuracy: 0.9252 - val_loss: 0.3812 - learning_rate: 1.2500e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8903 - loss: 0.4500 - val_accuracy: 0.9321 - val_loss: 0.3609 - learning_rate: 1.2500e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8914 - loss: 0.4397 - val_accuracy: 0.9347 - val_loss: 0.3592 - learning_rate: 1.2500e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8932 - loss: 0.4390 - val_accuracy: 0.9327 - val_loss: 0.3638 - learning_rate: 1.2500e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8982 - loss: 0.4305 - val_accuracy: 0.9359 - val_loss: 0.3632 - learning_rate: 1.2500e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8925 - loss: 0.4307 - val_accuracy: 0.9356 - val_loss: 0.3529 - learning_rate: 1.2500e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8981 - loss: 0.4218 - val_accuracy: 0.9347 - val_loss: 0.3574 - learning_rate: 1.2500e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9014 - loss: 0.4257 - val_accuracy: 0.9339 - val_loss: 0.3596 - learning_rate: 1.2500e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9003 - loss: 0.4221 - val_accuracy: 0.9356 - val_loss: 0.3549 - learning_rate: 1.2500e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9018 - loss: 0.4105 - val_accuracy: 0.9414 - val_loss: 0.3398 - learning_rate: 6.2500e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9059 - loss: 0.3992 - val_accuracy: 0.9391 - val_loss: 0.3355 - learning_rate: 6.2500e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9029 - loss: 0.4088 - val_accuracy: 0.9405 - val_loss: 0.3307 - learning_rate: 6.2500e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9087 - loss: 0.3913 - val_accuracy: 0.9420 - val_loss: 0.3299 - learning_rate: 6.2500e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9020 - loss: 0.4024 - val_accuracy: 0.9411 - val_loss: 0.3297 - learning_rate: 6.2500e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9078 - loss: 0.3948 - val_accuracy: 0.9417 - val_loss: 0.3277 - learning_rate: 6.2500e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9091 - loss: 0.3821 - val_accuracy: 0.9385 - val_loss: 0.3299 - learning_rate: 6.2500e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9124 - loss: 0.3751 - val_accuracy: 0.9374 - val_loss: 0.3305 - learning_rate: 6.2500e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9047 - loss: 0.3958 - val_accuracy: 0.9362 - val_loss: 0.3279 - learning_rate: 6.2500e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9122 - loss: 0.3752 - val_accuracy: 0.9420 - val_loss: 0.3206 - learning_rate: 3.1250e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9119 - loss: 0.3760 - val_accuracy: 0.9397 - val_loss: 0.3217 - learning_rate: 3.1250e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9142 - loss: 0.3741 - val_accuracy: 0.9420 - val_loss: 0.3168 - learning_rate: 3.1250e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.9156 - loss: 0.3649 - val_accuracy: 0.9449 - val_loss: 0.3127 - learning_rate: 3.1250e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9213 - loss: 0.3565 - val_accuracy: 0.9432 - val_loss: 0.3146 - learning_rate: 3.1250e-05\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "🧾 Fold 1 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.92      0.99      0.95       523\n",
      "     Jogging       0.95      0.87      0.90       565\n",
      "     Sitting       1.00      1.00      1.00       521\n",
      "    Standing       1.00      1.00      1.00       577\n",
      "    Upstairs       0.92      0.97      0.94       585\n",
      "     Walking       0.91      0.86      0.89       677\n",
      "\n",
      "    accuracy                           0.94      3448\n",
      "   macro avg       0.95      0.95      0.95      3448\n",
      "weighted avg       0.95      0.94      0.94      3448\n",
      "\n",
      "\n",
      "📚 Training Fold 2\n",
      "Epoch 1/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.4304 - loss: 3.8823 - val_accuracy: 0.3963 - val_loss: 1.7234 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.5544 - loss: 1.3273 - val_accuracy: 0.5724 - val_loss: 1.1723 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.5867 - loss: 1.1178 - val_accuracy: 0.6066 - val_loss: 1.1012 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6088 - loss: 1.0544 - val_accuracy: 0.5822 - val_loss: 1.0931 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6087 - loss: 1.0440 - val_accuracy: 0.6081 - val_loss: 1.0613 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.6161 - loss: 1.0404 - val_accuracy: 0.6153 - val_loss: 1.0526 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6138 - loss: 1.0334 - val_accuracy: 0.6406 - val_loss: 0.9888 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6361 - loss: 1.0203 - val_accuracy: 0.6310 - val_loss: 1.0111 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6345 - loss: 1.0188 - val_accuracy: 0.5907 - val_loss: 1.0815 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.6236 - loss: 1.0309 - val_accuracy: 0.6478 - val_loss: 1.0189 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6592 - loss: 0.9586 - val_accuracy: 0.6658 - val_loss: 0.9223 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6664 - loss: 0.8952 - val_accuracy: 0.6783 - val_loss: 0.8844 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6784 - loss: 0.8814 - val_accuracy: 0.6951 - val_loss: 0.8626 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6857 - loss: 0.8578 - val_accuracy: 0.7006 - val_loss: 0.8527 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6897 - loss: 0.8450 - val_accuracy: 0.6974 - val_loss: 0.8712 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.6966 - loss: 0.8479 - val_accuracy: 0.7064 - val_loss: 0.8456 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.6976 - loss: 0.8414 - val_accuracy: 0.7215 - val_loss: 0.8252 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.7111 - loss: 0.8235 - val_accuracy: 0.7200 - val_loss: 0.8251 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.7107 - loss: 0.8315 - val_accuracy: 0.7227 - val_loss: 0.8262 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7250 - loss: 0.8111 - val_accuracy: 0.7279 - val_loss: 0.8252 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7360 - loss: 0.7859 - val_accuracy: 0.7778 - val_loss: 0.7368 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7503 - loss: 0.7486 - val_accuracy: 0.7615 - val_loss: 0.7306 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7515 - loss: 0.7280 - val_accuracy: 0.7842 - val_loss: 0.6949 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7657 - loss: 0.7043 - val_accuracy: 0.7963 - val_loss: 0.6813 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7765 - loss: 0.6938 - val_accuracy: 0.7969 - val_loss: 0.6724 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7717 - loss: 0.6955 - val_accuracy: 0.7830 - val_loss: 0.6883 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7736 - loss: 0.6906 - val_accuracy: 0.8114 - val_loss: 0.6546 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7922 - loss: 0.6656 - val_accuracy: 0.8138 - val_loss: 0.6371 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7960 - loss: 0.6545 - val_accuracy: 0.8375 - val_loss: 0.6178 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7952 - loss: 0.6522 - val_accuracy: 0.8268 - val_loss: 0.6234 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8028 - loss: 0.6499 - val_accuracy: 0.8335 - val_loss: 0.6089 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8030 - loss: 0.6455 - val_accuracy: 0.8352 - val_loss: 0.5992 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8127 - loss: 0.6154 - val_accuracy: 0.8335 - val_loss: 0.6016 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8102 - loss: 0.6227 - val_accuracy: 0.8506 - val_loss: 0.5831 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8275 - loss: 0.6082 - val_accuracy: 0.8468 - val_loss: 0.5825 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8190 - loss: 0.6149 - val_accuracy: 0.8573 - val_loss: 0.5515 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8180 - loss: 0.6222 - val_accuracy: 0.8697 - val_loss: 0.5525 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8267 - loss: 0.6010 - val_accuracy: 0.8663 - val_loss: 0.5482 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8319 - loss: 0.5977 - val_accuracy: 0.8741 - val_loss: 0.5387 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8325 - loss: 0.5927 - val_accuracy: 0.8828 - val_loss: 0.5216 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8460 - loss: 0.5816 - val_accuracy: 0.8674 - val_loss: 0.5439 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8364 - loss: 0.5925 - val_accuracy: 0.8840 - val_loss: 0.5176 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8450 - loss: 0.5723 - val_accuracy: 0.8842 - val_loss: 0.5177 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8387 - loss: 0.5821 - val_accuracy: 0.8764 - val_loss: 0.5252 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8409 - loss: 0.5695 - val_accuracy: 0.8813 - val_loss: 0.5214 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8619 - loss: 0.5444 - val_accuracy: 0.9080 - val_loss: 0.4627 - learning_rate: 1.2500e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8677 - loss: 0.5171 - val_accuracy: 0.9034 - val_loss: 0.4512 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8770 - loss: 0.4991 - val_accuracy: 0.9115 - val_loss: 0.4475 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8760 - loss: 0.5009 - val_accuracy: 0.9156 - val_loss: 0.4335 - learning_rate: 1.2500e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8712 - loss: 0.5158 - val_accuracy: 0.9133 - val_loss: 0.4288 - learning_rate: 1.2500e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8737 - loss: 0.5012 - val_accuracy: 0.9191 - val_loss: 0.4259 - learning_rate: 1.2500e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8849 - loss: 0.4721 - val_accuracy: 0.9205 - val_loss: 0.4174 - learning_rate: 1.2500e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8809 - loss: 0.4778 - val_accuracy: 0.9194 - val_loss: 0.4133 - learning_rate: 1.2500e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8773 - loss: 0.4851 - val_accuracy: 0.9185 - val_loss: 0.4207 - learning_rate: 1.2500e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8749 - loss: 0.4799 - val_accuracy: 0.9234 - val_loss: 0.4052 - learning_rate: 1.2500e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8780 - loss: 0.4804 - val_accuracy: 0.9173 - val_loss: 0.4027 - learning_rate: 1.2500e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8799 - loss: 0.4687 - val_accuracy: 0.9191 - val_loss: 0.4034 - learning_rate: 1.2500e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8752 - loss: 0.4768 - val_accuracy: 0.9205 - val_loss: 0.4057 - learning_rate: 1.2500e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8916 - loss: 0.4591 - val_accuracy: 0.9246 - val_loss: 0.3921 - learning_rate: 1.2500e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8897 - loss: 0.4503 - val_accuracy: 0.9237 - val_loss: 0.3985 - learning_rate: 1.2500e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8898 - loss: 0.4476 - val_accuracy: 0.9304 - val_loss: 0.3821 - learning_rate: 1.2500e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8831 - loss: 0.4663 - val_accuracy: 0.9266 - val_loss: 0.3854 - learning_rate: 1.2500e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8924 - loss: 0.4411 - val_accuracy: 0.9341 - val_loss: 0.3713 - learning_rate: 1.2500e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.8894 - loss: 0.4507 - val_accuracy: 0.9298 - val_loss: 0.3781 - learning_rate: 1.2500e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8929 - loss: 0.4446 - val_accuracy: 0.9266 - val_loss: 0.3869 - learning_rate: 1.2500e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8919 - loss: 0.4497 - val_accuracy: 0.9164 - val_loss: 0.4093 - learning_rate: 1.2500e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8947 - loss: 0.4310 - val_accuracy: 0.9350 - val_loss: 0.3619 - learning_rate: 6.2500e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8986 - loss: 0.4239 - val_accuracy: 0.9324 - val_loss: 0.3612 - learning_rate: 6.2500e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9045 - loss: 0.4127 - val_accuracy: 0.9350 - val_loss: 0.3543 - learning_rate: 6.2500e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9083 - loss: 0.3998 - val_accuracy: 0.9402 - val_loss: 0.3462 - learning_rate: 6.2500e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9081 - loss: 0.3970 - val_accuracy: 0.9391 - val_loss: 0.3387 - learning_rate: 6.2500e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9081 - loss: 0.3970 - val_accuracy: 0.9405 - val_loss: 0.3357 - learning_rate: 6.2500e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.9068 - loss: 0.3995 - val_accuracy: 0.9417 - val_loss: 0.3378 - learning_rate: 6.2500e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9084 - loss: 0.3946 - val_accuracy: 0.9405 - val_loss: 0.3411 - learning_rate: 6.2500e-05\n",
      "Epoch 75/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9054 - loss: 0.3978 - val_accuracy: 0.9431 - val_loss: 0.3360 - learning_rate: 6.2500e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9078 - loss: 0.3893 - val_accuracy: 0.9431 - val_loss: 0.3318 - learning_rate: 3.1250e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9087 - loss: 0.3791 - val_accuracy: 0.9455 - val_loss: 0.3274 - learning_rate: 3.1250e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9118 - loss: 0.3828 - val_accuracy: 0.9466 - val_loss: 0.3232 - learning_rate: 3.1250e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9159 - loss: 0.3768 - val_accuracy: 0.9449 - val_loss: 0.3306 - learning_rate: 3.1250e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9151 - loss: 0.3778 - val_accuracy: 0.9428 - val_loss: 0.3313 - learning_rate: 3.1250e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9154 - loss: 0.3694 - val_accuracy: 0.9469 - val_loss: 0.3199 - learning_rate: 3.1250e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9194 - loss: 0.3624 - val_accuracy: 0.9489 - val_loss: 0.3153 - learning_rate: 3.1250e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9145 - loss: 0.3743 - val_accuracy: 0.9463 - val_loss: 0.3208 - learning_rate: 3.1250e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9190 - loss: 0.3592 - val_accuracy: 0.9501 - val_loss: 0.3118 - learning_rate: 3.1250e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.9138 - loss: 0.3732 - val_accuracy: 0.9457 - val_loss: 0.3185 - learning_rate: 3.1250e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9188 - loss: 0.3491 - val_accuracy: 0.9475 - val_loss: 0.3147 - learning_rate: 3.1250e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9128 - loss: 0.3695 - val_accuracy: 0.9507 - val_loss: 0.3107 - learning_rate: 3.1250e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.9169 - loss: 0.3605 - val_accuracy: 0.9489 - val_loss: 0.3129 - learning_rate: 3.1250e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9216 - loss: 0.3559 - val_accuracy: 0.9469 - val_loss: 0.3121 - learning_rate: 3.1250e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.9202 - loss: 0.3568 - val_accuracy: 0.9475 - val_loss: 0.3138 - learning_rate: 3.1250e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9187 - loss: 0.3542 - val_accuracy: 0.9492 - val_loss: 0.3131 - learning_rate: 1.5625e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9231 - loss: 0.3524 - val_accuracy: 0.9495 - val_loss: 0.3090 - learning_rate: 1.5625e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.9221 - loss: 0.3478 - val_accuracy: 0.9524 - val_loss: 0.3013 - learning_rate: 1.5625e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - accuracy: 0.9188 - loss: 0.3594 - val_accuracy: 0.9510 - val_loss: 0.3061 - learning_rate: 1.5625e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9200 - loss: 0.3579 - val_accuracy: 0.9513 - val_loss: 0.3032 - learning_rate: 1.5625e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9154 - loss: 0.3589 - val_accuracy: 0.9547 - val_loss: 0.2976 - learning_rate: 1.5625e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.9239 - loss: 0.3475 - val_accuracy: 0.9510 - val_loss: 0.3029 - learning_rate: 1.5625e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.9248 - loss: 0.3463 - val_accuracy: 0.9530 - val_loss: 0.3015 - learning_rate: 1.5625e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.9235 - loss: 0.3458 - val_accuracy: 0.9489 - val_loss: 0.3020 - learning_rate: 1.5625e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9192 - loss: 0.3476 - val_accuracy: 0.9507 - val_loss: 0.3023 - learning_rate: 7.8125e-06\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n",
      "\n",
      "🧾 Fold 2 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.93      0.99      0.96       522\n",
      "     Jogging       0.96      0.87      0.91       565\n",
      "     Sitting       1.00      1.00      1.00       522\n",
      "    Standing       1.00      1.00      1.00       576\n",
      "    Upstairs       0.92      0.99      0.96       586\n",
      "     Walking       0.92      0.89      0.91       676\n",
      "\n",
      "    accuracy                           0.95      3447\n",
      "   macro avg       0.96      0.96      0.96      3447\n",
      "weighted avg       0.96      0.95      0.95      3447\n",
      "\n",
      "\n",
      "📚 Training Fold 3\n",
      "Epoch 1/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.4258 - loss: 3.8917 - val_accuracy: 0.4276 - val_loss: 1.7672 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.5549 - loss: 1.3170 - val_accuracy: 0.5785 - val_loss: 1.2048 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.5719 - loss: 1.1523 - val_accuracy: 0.5384 - val_loss: 1.2009 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.5947 - loss: 1.0745 - val_accuracy: 0.6484 - val_loss: 0.9797 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6008 - loss: 1.0591 - val_accuracy: 0.6365 - val_loss: 1.0110 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.6101 - loss: 1.0451 - val_accuracy: 0.6533 - val_loss: 0.9650 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.6305 - loss: 1.0215 - val_accuracy: 0.6475 - val_loss: 0.9940 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.6324 - loss: 1.0104 - val_accuracy: 0.6551 - val_loss: 0.9757 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.6365 - loss: 1.0175 - val_accuracy: 0.6414 - val_loss: 0.9773 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.6609 - loss: 0.9484 - val_accuracy: 0.6820 - val_loss: 0.8881 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.6798 - loss: 0.8876 - val_accuracy: 0.7058 - val_loss: 0.8358 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6822 - loss: 0.8852 - val_accuracy: 0.7131 - val_loss: 0.8310 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6825 - loss: 0.8753 - val_accuracy: 0.7186 - val_loss: 0.8183 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6981 - loss: 0.8562 - val_accuracy: 0.7041 - val_loss: 0.8537 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7018 - loss: 0.8441 - val_accuracy: 0.7058 - val_loss: 0.8284 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7053 - loss: 0.8534 - val_accuracy: 0.7334 - val_loss: 0.8040 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7147 - loss: 0.8436 - val_accuracy: 0.7305 - val_loss: 0.8167 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7151 - loss: 0.8399 - val_accuracy: 0.7531 - val_loss: 0.7712 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7265 - loss: 0.8172 - val_accuracy: 0.7566 - val_loss: 0.7753 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7246 - loss: 0.8194 - val_accuracy: 0.7621 - val_loss: 0.7714 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7276 - loss: 0.8243 - val_accuracy: 0.7714 - val_loss: 0.7598 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7354 - loss: 0.8165 - val_accuracy: 0.7708 - val_loss: 0.7543 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7370 - loss: 0.8059 - val_accuracy: 0.7749 - val_loss: 0.7644 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7507 - loss: 0.7980 - val_accuracy: 0.7836 - val_loss: 0.7460 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7597 - loss: 0.7804 - val_accuracy: 0.7850 - val_loss: 0.7355 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7615 - loss: 0.7849 - val_accuracy: 0.7891 - val_loss: 0.7418 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7663 - loss: 0.7770 - val_accuracy: 0.7641 - val_loss: 0.7855 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7630 - loss: 0.7856 - val_accuracy: 0.7833 - val_loss: 0.7412 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7842 - loss: 0.7369 - val_accuracy: 0.8262 - val_loss: 0.6598 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8023 - loss: 0.6877 - val_accuracy: 0.8422 - val_loss: 0.6350 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8103 - loss: 0.6650 - val_accuracy: 0.8477 - val_loss: 0.6071 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8140 - loss: 0.6619 - val_accuracy: 0.8506 - val_loss: 0.5993 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8243 - loss: 0.6401 - val_accuracy: 0.8622 - val_loss: 0.5919 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8228 - loss: 0.6325 - val_accuracy: 0.8573 - val_loss: 0.5851 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8208 - loss: 0.6354 - val_accuracy: 0.8761 - val_loss: 0.5590 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8288 - loss: 0.6190 - val_accuracy: 0.8726 - val_loss: 0.5414 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8341 - loss: 0.6092 - val_accuracy: 0.8796 - val_loss: 0.5495 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8420 - loss: 0.5976 - val_accuracy: 0.8782 - val_loss: 0.5450 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8376 - loss: 0.5933 - val_accuracy: 0.8767 - val_loss: 0.5407 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8476 - loss: 0.5778 - val_accuracy: 0.9011 - val_loss: 0.5064 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8438 - loss: 0.5878 - val_accuracy: 0.8712 - val_loss: 0.5459 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8473 - loss: 0.5807 - val_accuracy: 0.8863 - val_loss: 0.5312 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8458 - loss: 0.5926 - val_accuracy: 0.8941 - val_loss: 0.5056 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8551 - loss: 0.5654 - val_accuracy: 0.8961 - val_loss: 0.5032 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8483 - loss: 0.5795 - val_accuracy: 0.8883 - val_loss: 0.5083 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8450 - loss: 0.5810 - val_accuracy: 0.9066 - val_loss: 0.4842 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.8571 - loss: 0.5578 - val_accuracy: 0.8967 - val_loss: 0.4926 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.8633 - loss: 0.5421 - val_accuracy: 0.9057 - val_loss: 0.4768 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 54ms/step - accuracy: 0.8729 - loss: 0.5375 - val_accuracy: 0.9046 - val_loss: 0.4759 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8731 - loss: 0.5275 - val_accuracy: 0.9115 - val_loss: 0.4601 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.8646 - loss: 0.5479 - val_accuracy: 0.9150 - val_loss: 0.4598 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8606 - loss: 0.5586 - val_accuracy: 0.9069 - val_loss: 0.4811 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.8688 - loss: 0.5392 - val_accuracy: 0.9138 - val_loss: 0.4630 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.8750 - loss: 0.5281 - val_accuracy: 0.9135 - val_loss: 0.4604 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.8763 - loss: 0.5173 - val_accuracy: 0.9266 - val_loss: 0.4209 - learning_rate: 1.2500e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.8849 - loss: 0.4850 - val_accuracy: 0.9202 - val_loss: 0.4189 - learning_rate: 1.2500e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 75ms/step - accuracy: 0.8870 - loss: 0.4816 - val_accuracy: 0.9275 - val_loss: 0.4094 - learning_rate: 1.2500e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 58ms/step - accuracy: 0.8906 - loss: 0.4800 - val_accuracy: 0.9202 - val_loss: 0.4154 - learning_rate: 1.2500e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.8910 - loss: 0.4656 - val_accuracy: 0.9234 - val_loss: 0.4026 - learning_rate: 1.2500e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8993 - loss: 0.4572 - val_accuracy: 0.9286 - val_loss: 0.3927 - learning_rate: 1.2500e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8990 - loss: 0.4506 - val_accuracy: 0.9191 - val_loss: 0.4073 - learning_rate: 1.2500e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.8995 - loss: 0.4615 - val_accuracy: 0.9266 - val_loss: 0.4006 - learning_rate: 1.2500e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.8943 - loss: 0.4492 - val_accuracy: 0.9330 - val_loss: 0.3769 - learning_rate: 1.2500e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9004 - loss: 0.4366 - val_accuracy: 0.9356 - val_loss: 0.3718 - learning_rate: 1.2500e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.8990 - loss: 0.4401 - val_accuracy: 0.9324 - val_loss: 0.3822 - learning_rate: 1.2500e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9040 - loss: 0.4317 - val_accuracy: 0.9365 - val_loss: 0.3694 - learning_rate: 1.2500e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.8957 - loss: 0.4400 - val_accuracy: 0.9373 - val_loss: 0.3679 - learning_rate: 1.2500e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9068 - loss: 0.4206 - val_accuracy: 0.9347 - val_loss: 0.3656 - learning_rate: 1.2500e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8935 - loss: 0.4530 - val_accuracy: 0.9382 - val_loss: 0.3610 - learning_rate: 1.2500e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9068 - loss: 0.4170 - val_accuracy: 0.9411 - val_loss: 0.3496 - learning_rate: 1.2500e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9058 - loss: 0.4179 - val_accuracy: 0.9379 - val_loss: 0.3518 - learning_rate: 1.2500e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9086 - loss: 0.4131 - val_accuracy: 0.9382 - val_loss: 0.3594 - learning_rate: 1.2500e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9028 - loss: 0.4214 - val_accuracy: 0.9420 - val_loss: 0.3490 - learning_rate: 1.2500e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9109 - loss: 0.4084 - val_accuracy: 0.9408 - val_loss: 0.3503 - learning_rate: 1.2500e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9055 - loss: 0.4170 - val_accuracy: 0.9434 - val_loss: 0.3448 - learning_rate: 1.2500e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9082 - loss: 0.4110 - val_accuracy: 0.9417 - val_loss: 0.3319 - learning_rate: 1.2500e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9125 - loss: 0.3952 - val_accuracy: 0.9466 - val_loss: 0.3390 - learning_rate: 1.2500e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9077 - loss: 0.4171 - val_accuracy: 0.9388 - val_loss: 0.3429 - learning_rate: 1.2500e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9099 - loss: 0.4106 - val_accuracy: 0.9434 - val_loss: 0.3403 - learning_rate: 1.2500e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9102 - loss: 0.3967 - val_accuracy: 0.9402 - val_loss: 0.3404 - learning_rate: 6.2500e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9160 - loss: 0.3862 - val_accuracy: 0.9469 - val_loss: 0.3261 - learning_rate: 6.2500e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9145 - loss: 0.3776 - val_accuracy: 0.9434 - val_loss: 0.3305 - learning_rate: 6.2500e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9269 - loss: 0.3586 - val_accuracy: 0.9428 - val_loss: 0.3284 - learning_rate: 6.2500e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9206 - loss: 0.3691 - val_accuracy: 0.9460 - val_loss: 0.3209 - learning_rate: 6.2500e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9233 - loss: 0.3703 - val_accuracy: 0.9481 - val_loss: 0.3189 - learning_rate: 6.2500e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9256 - loss: 0.3632 - val_accuracy: 0.9472 - val_loss: 0.3175 - learning_rate: 6.2500e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9182 - loss: 0.3708 - val_accuracy: 0.9475 - val_loss: 0.3171 - learning_rate: 6.2500e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9324 - loss: 0.3437 - val_accuracy: 0.9469 - val_loss: 0.3140 - learning_rate: 6.2500e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9209 - loss: 0.3700 - val_accuracy: 0.9501 - val_loss: 0.3102 - learning_rate: 6.2500e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9261 - loss: 0.3536 - val_accuracy: 0.9472 - val_loss: 0.3133 - learning_rate: 6.2500e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9226 - loss: 0.3535 - val_accuracy: 0.9475 - val_loss: 0.3075 - learning_rate: 6.2500e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9232 - loss: 0.3581 - val_accuracy: 0.9516 - val_loss: 0.3078 - learning_rate: 6.2500e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9231 - loss: 0.3477 - val_accuracy: 0.9536 - val_loss: 0.3011 - learning_rate: 6.2500e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.9316 - loss: 0.3439 - val_accuracy: 0.9542 - val_loss: 0.3001 - learning_rate: 6.2500e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.9333 - loss: 0.3339 - val_accuracy: 0.9516 - val_loss: 0.3019 - learning_rate: 6.2500e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.9204 - loss: 0.3542 - val_accuracy: 0.9530 - val_loss: 0.2982 - learning_rate: 6.2500e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.9247 - loss: 0.3460 - val_accuracy: 0.9475 - val_loss: 0.3064 - learning_rate: 6.2500e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9310 - loss: 0.3421 - val_accuracy: 0.9547 - val_loss: 0.2971 - learning_rate: 6.2500e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9320 - loss: 0.3318 - val_accuracy: 0.9556 - val_loss: 0.2914 - learning_rate: 6.2500e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9299 - loss: 0.3324 - val_accuracy: 0.9524 - val_loss: 0.2989 - learning_rate: 6.2500e-05\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
      "\n",
      "🧾 Fold 3 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.94      1.00      0.97       522\n",
      "     Jogging       0.95      0.91      0.93       565\n",
      "     Sitting       1.00      1.00      1.00       521\n",
      "    Standing       0.99      1.00      1.00       577\n",
      "    Upstairs       0.92      0.98      0.95       586\n",
      "     Walking       0.93      0.86      0.90       676\n",
      "\n",
      "    accuracy                           0.96      3447\n",
      "   macro avg       0.96      0.96      0.96      3447\n",
      "weighted avg       0.96      0.96      0.96      3447\n",
      "\n",
      "\n",
      "📚 Training Fold 4\n",
      "Epoch 1/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 36ms/step - accuracy: 0.4154 - loss: 3.8304 - val_accuracy: 0.4111 - val_loss: 1.7146 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.5458 - loss: 1.3246 - val_accuracy: 0.5631 - val_loss: 1.1789 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.5829 - loss: 1.1343 - val_accuracy: 0.5921 - val_loss: 1.0928 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.5910 - loss: 1.0967 - val_accuracy: 0.6028 - val_loss: 1.0675 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.5996 - loss: 1.0669 - val_accuracy: 0.6310 - val_loss: 1.0101 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.6149 - loss: 1.0346 - val_accuracy: 0.6504 - val_loss: 1.0021 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.6227 - loss: 1.0269 - val_accuracy: 0.6414 - val_loss: 1.0008 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.6302 - loss: 1.0140 - val_accuracy: 0.6493 - val_loss: 0.9898 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.6403 - loss: 1.0032 - val_accuracy: 0.6249 - val_loss: 1.0207 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.6273 - loss: 1.0182 - val_accuracy: 0.6536 - val_loss: 0.9848 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.6379 - loss: 1.0091 - val_accuracy: 0.6510 - val_loss: 0.9795 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.6321 - loss: 1.0306 - val_accuracy: 0.6858 - val_loss: 0.9405 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.6476 - loss: 0.9927 - val_accuracy: 0.6681 - val_loss: 0.9689 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6499 - loss: 0.9906 - val_accuracy: 0.6667 - val_loss: 0.9384 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.6550 - loss: 0.9738 - val_accuracy: 0.6699 - val_loss: 0.9770 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.6737 - loss: 0.9628 - val_accuracy: 0.6948 - val_loss: 0.9141 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.6718 - loss: 0.9533 - val_accuracy: 0.6905 - val_loss: 0.9532 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6676 - loss: 0.9698 - val_accuracy: 0.7116 - val_loss: 0.8978 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.6643 - loss: 0.9734 - val_accuracy: 0.6765 - val_loss: 0.9428 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6739 - loss: 0.9485 - val_accuracy: 0.6928 - val_loss: 0.9340 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6683 - loss: 0.9562 - val_accuracy: 0.6960 - val_loss: 0.9157 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.6953 - loss: 0.9000 - val_accuracy: 0.7200 - val_loss: 0.8422 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7121 - loss: 0.8349 - val_accuracy: 0.7250 - val_loss: 0.8191 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.7132 - loss: 0.8211 - val_accuracy: 0.7479 - val_loss: 0.7725 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.7221 - loss: 0.8029 - val_accuracy: 0.7459 - val_loss: 0.7679 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.7303 - loss: 0.7950 - val_accuracy: 0.7572 - val_loss: 0.7581 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7275 - loss: 0.7940 - val_accuracy: 0.7610 - val_loss: 0.7623 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7326 - loss: 0.7841 - val_accuracy: 0.7688 - val_loss: 0.7557 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7419 - loss: 0.7743 - val_accuracy: 0.7842 - val_loss: 0.7233 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7407 - loss: 0.7733 - val_accuracy: 0.7740 - val_loss: 0.7286 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7472 - loss: 0.7706 - val_accuracy: 0.7905 - val_loss: 0.7052 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7627 - loss: 0.7525 - val_accuracy: 0.7818 - val_loss: 0.7378 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7534 - loss: 0.7617 - val_accuracy: 0.7847 - val_loss: 0.7350 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.7601 - loss: 0.7415 - val_accuracy: 0.8111 - val_loss: 0.6943 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7640 - loss: 0.7493 - val_accuracy: 0.8135 - val_loss: 0.6913 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7754 - loss: 0.7241 - val_accuracy: 0.8024 - val_loss: 0.6949 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7690 - loss: 0.7426 - val_accuracy: 0.8100 - val_loss: 0.6837 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7773 - loss: 0.7282 - val_accuracy: 0.8155 - val_loss: 0.6838 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7807 - loss: 0.7262 - val_accuracy: 0.8233 - val_loss: 0.6738 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.7748 - loss: 0.7259 - val_accuracy: 0.8265 - val_loss: 0.6669 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.7795 - loss: 0.7208 - val_accuracy: 0.8271 - val_loss: 0.6663 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.7824 - loss: 0.7276 - val_accuracy: 0.8248 - val_loss: 0.6642 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.7897 - loss: 0.7172 - val_accuracy: 0.8416 - val_loss: 0.6562 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7903 - loss: 0.7047 - val_accuracy: 0.8187 - val_loss: 0.6704 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7931 - loss: 0.7006 - val_accuracy: 0.8201 - val_loss: 0.6710 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.7990 - loss: 0.7047 - val_accuracy: 0.8236 - val_loss: 0.6585 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.8021 - loss: 0.6772 - val_accuracy: 0.8462 - val_loss: 0.5996 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8253 - loss: 0.6308 - val_accuracy: 0.8610 - val_loss: 0.5644 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8340 - loss: 0.6044 - val_accuracy: 0.8677 - val_loss: 0.5610 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8272 - loss: 0.6076 - val_accuracy: 0.8721 - val_loss: 0.5449 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8434 - loss: 0.5767 - val_accuracy: 0.8831 - val_loss: 0.5263 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.8345 - loss: 0.5880 - val_accuracy: 0.8796 - val_loss: 0.5323 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8419 - loss: 0.5720 - val_accuracy: 0.8767 - val_loss: 0.5286 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8417 - loss: 0.5809 - val_accuracy: 0.8863 - val_loss: 0.5180 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8330 - loss: 0.5860 - val_accuracy: 0.8828 - val_loss: 0.5125 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8478 - loss: 0.5628 - val_accuracy: 0.8793 - val_loss: 0.5162 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8407 - loss: 0.5685 - val_accuracy: 0.8924 - val_loss: 0.5006 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8366 - loss: 0.5704 - val_accuracy: 0.8964 - val_loss: 0.4930 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8545 - loss: 0.5444 - val_accuracy: 0.8999 - val_loss: 0.4843 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.8526 - loss: 0.5512 - val_accuracy: 0.8976 - val_loss: 0.4845 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.8496 - loss: 0.5572 - val_accuracy: 0.8782 - val_loss: 0.5165 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.8477 - loss: 0.5461 - val_accuracy: 0.9054 - val_loss: 0.4660 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.8476 - loss: 0.5534 - val_accuracy: 0.9083 - val_loss: 0.4621 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8487 - loss: 0.5462 - val_accuracy: 0.8990 - val_loss: 0.4677 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8608 - loss: 0.5266 - val_accuracy: 0.9005 - val_loss: 0.4545 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8590 - loss: 0.5245 - val_accuracy: 0.8964 - val_loss: 0.4555 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8560 - loss: 0.5381 - val_accuracy: 0.8961 - val_loss: 0.4682 - learning_rate: 2.5000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8563 - loss: 0.5278 - val_accuracy: 0.9089 - val_loss: 0.4511 - learning_rate: 2.5000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8594 - loss: 0.5250 - val_accuracy: 0.9040 - val_loss: 0.4549 - learning_rate: 2.5000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8565 - loss: 0.5306 - val_accuracy: 0.8889 - val_loss: 0.4827 - learning_rate: 2.5000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8604 - loss: 0.5339 - val_accuracy: 0.9133 - val_loss: 0.4375 - learning_rate: 2.5000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.8638 - loss: 0.5173 - val_accuracy: 0.9162 - val_loss: 0.4401 - learning_rate: 2.5000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8600 - loss: 0.5240 - val_accuracy: 0.9048 - val_loss: 0.4564 - learning_rate: 2.5000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8645 - loss: 0.5180 - val_accuracy: 0.9098 - val_loss: 0.4426 - learning_rate: 2.5000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 56ms/step - accuracy: 0.8704 - loss: 0.4930 - val_accuracy: 0.9162 - val_loss: 0.4176 - learning_rate: 1.2500e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - accuracy: 0.8726 - loss: 0.4961 - val_accuracy: 0.9196 - val_loss: 0.4067 - learning_rate: 1.2500e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8845 - loss: 0.4581 - val_accuracy: 0.9208 - val_loss: 0.3982 - learning_rate: 1.2500e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.8795 - loss: 0.4717 - val_accuracy: 0.9231 - val_loss: 0.3884 - learning_rate: 1.2500e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8835 - loss: 0.4639 - val_accuracy: 0.9223 - val_loss: 0.3954 - learning_rate: 1.2500e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.8846 - loss: 0.4522 - val_accuracy: 0.9217 - val_loss: 0.3940 - learning_rate: 1.2500e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8798 - loss: 0.4572 - val_accuracy: 0.9292 - val_loss: 0.3836 - learning_rate: 1.2500e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.8887 - loss: 0.4490 - val_accuracy: 0.9269 - val_loss: 0.3827 - learning_rate: 1.2500e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.8921 - loss: 0.4365 - val_accuracy: 0.9254 - val_loss: 0.3823 - learning_rate: 1.2500e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 0.8899 - loss: 0.4333 - val_accuracy: 0.9243 - val_loss: 0.3884 - learning_rate: 1.2500e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.8855 - loss: 0.4490 - val_accuracy: 0.9228 - val_loss: 0.3800 - learning_rate: 1.2500e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.8873 - loss: 0.4441 - val_accuracy: 0.9283 - val_loss: 0.3629 - learning_rate: 1.2500e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8915 - loss: 0.4357 - val_accuracy: 0.9249 - val_loss: 0.3688 - learning_rate: 1.2500e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8909 - loss: 0.4318 - val_accuracy: 0.9321 - val_loss: 0.3612 - learning_rate: 1.2500e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.8909 - loss: 0.4312 - val_accuracy: 0.9307 - val_loss: 0.3543 - learning_rate: 1.2500e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8871 - loss: 0.4405 - val_accuracy: 0.9252 - val_loss: 0.3724 - learning_rate: 1.2500e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.8913 - loss: 0.4247 - val_accuracy: 0.9391 - val_loss: 0.3472 - learning_rate: 1.2500e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8872 - loss: 0.4389 - val_accuracy: 0.9368 - val_loss: 0.3484 - learning_rate: 1.2500e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8950 - loss: 0.4178 - val_accuracy: 0.9289 - val_loss: 0.3642 - learning_rate: 1.2500e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.8950 - loss: 0.4177 - val_accuracy: 0.9359 - val_loss: 0.3499 - learning_rate: 1.2500e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9050 - loss: 0.3993 - val_accuracy: 0.9382 - val_loss: 0.3365 - learning_rate: 6.2500e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9043 - loss: 0.3911 - val_accuracy: 0.9376 - val_loss: 0.3420 - learning_rate: 6.2500e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9051 - loss: 0.3915 - val_accuracy: 0.9353 - val_loss: 0.3358 - learning_rate: 6.2500e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9072 - loss: 0.3854 - val_accuracy: 0.9379 - val_loss: 0.3322 - learning_rate: 6.2500e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9080 - loss: 0.3782 - val_accuracy: 0.9411 - val_loss: 0.3249 - learning_rate: 6.2500e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9054 - loss: 0.3836 - val_accuracy: 0.9339 - val_loss: 0.3386 - learning_rate: 6.2500e-05\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "🧾 Fold 4 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.90      0.99      0.94       522\n",
      "     Jogging       0.94      0.85      0.90       565\n",
      "     Sitting       1.00      1.00      1.00       521\n",
      "    Standing       0.99      1.00      1.00       577\n",
      "    Upstairs       0.91      0.98      0.94       586\n",
      "     Walking       0.91      0.85      0.88       676\n",
      "\n",
      "    accuracy                           0.94      3447\n",
      "   macro avg       0.94      0.95      0.94      3447\n",
      "weighted avg       0.94      0.94      0.94      3447\n",
      "\n",
      "\n",
      "📚 Training Fold 5\n",
      "Epoch 1/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4196 - loss: 3.8697 - val_accuracy: 0.3777 - val_loss: 1.7583 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.5345 - loss: 1.3240 - val_accuracy: 0.6191 - val_loss: 1.1468 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - accuracy: 0.5871 - loss: 1.1144 - val_accuracy: 0.6046 - val_loss: 1.0637 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.5963 - loss: 1.0843 - val_accuracy: 0.6034 - val_loss: 1.0489 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.6054 - loss: 1.0497 - val_accuracy: 0.6031 - val_loss: 1.0718 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.6120 - loss: 1.0426 - val_accuracy: 0.6278 - val_loss: 0.9951 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6254 - loss: 1.0161 - val_accuracy: 0.6249 - val_loss: 1.0001 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.6276 - loss: 1.0215 - val_accuracy: 0.6527 - val_loss: 0.9965 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6253 - loss: 1.0298 - val_accuracy: 0.6501 - val_loss: 0.9895 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 1.0044 - val_accuracy: 0.6504 - val_loss: 0.9887 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.6334 - loss: 1.0203 - val_accuracy: 0.6678 - val_loss: 0.9655 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.6390 - loss: 1.0003 - val_accuracy: 0.6675 - val_loss: 0.9544 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.6481 - loss: 0.9910 - val_accuracy: 0.6588 - val_loss: 0.9999 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6410 - loss: 1.0101 - val_accuracy: 0.6876 - val_loss: 0.9410 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.6622 - loss: 0.9737 - val_accuracy: 0.7041 - val_loss: 0.9103 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.6544 - loss: 0.9884 - val_accuracy: 0.6881 - val_loss: 0.9318 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.6635 - loss: 0.9771 - val_accuracy: 0.6623 - val_loss: 0.9625 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.6617 - loss: 0.9667 - val_accuracy: 0.6789 - val_loss: 0.9364 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.6711 - loss: 0.9311 - val_accuracy: 0.7209 - val_loss: 0.8294 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.7023 - loss: 0.8521 - val_accuracy: 0.7351 - val_loss: 0.7871 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.7118 - loss: 0.8301 - val_accuracy: 0.7470 - val_loss: 0.7832 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.7146 - loss: 0.8171 - val_accuracy: 0.7546 - val_loss: 0.7703 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.7213 - loss: 0.8189 - val_accuracy: 0.7557 - val_loss: 0.7650 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.7244 - loss: 0.8140 - val_accuracy: 0.7598 - val_loss: 0.7579 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.7286 - loss: 0.8115 - val_accuracy: 0.7618 - val_loss: 0.7396 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.7297 - loss: 0.7969 - val_accuracy: 0.7493 - val_loss: 0.7716 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7372 - loss: 0.8007 - val_accuracy: 0.7615 - val_loss: 0.7540 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.7469 - loss: 0.7874 - val_accuracy: 0.7743 - val_loss: 0.7438 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.7553 - loss: 0.7515 - val_accuracy: 0.7882 - val_loss: 0.6851 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.7697 - loss: 0.7166 - val_accuracy: 0.8167 - val_loss: 0.6492 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.7760 - loss: 0.7054 - val_accuracy: 0.8132 - val_loss: 0.6505 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7860 - loss: 0.6769 - val_accuracy: 0.8161 - val_loss: 0.6301 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7753 - loss: 0.6850 - val_accuracy: 0.8256 - val_loss: 0.6207 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7946 - loss: 0.6618 - val_accuracy: 0.8372 - val_loss: 0.5953 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7939 - loss: 0.6536 - val_accuracy: 0.8323 - val_loss: 0.5986 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8055 - loss: 0.6351 - val_accuracy: 0.8416 - val_loss: 0.5811 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8047 - loss: 0.6343 - val_accuracy: 0.8500 - val_loss: 0.5676 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8097 - loss: 0.6297 - val_accuracy: 0.8436 - val_loss: 0.5674 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8096 - loss: 0.6257 - val_accuracy: 0.8431 - val_loss: 0.5704 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8179 - loss: 0.6165 - val_accuracy: 0.8549 - val_loss: 0.5586 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8190 - loss: 0.6172 - val_accuracy: 0.8674 - val_loss: 0.5392 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8293 - loss: 0.5932 - val_accuracy: 0.8584 - val_loss: 0.5420 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8236 - loss: 0.5993 - val_accuracy: 0.8689 - val_loss: 0.5328 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8261 - loss: 0.5971 - val_accuracy: 0.8744 - val_loss: 0.5344 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8299 - loss: 0.5960 - val_accuracy: 0.8790 - val_loss: 0.5217 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8246 - loss: 0.5984 - val_accuracy: 0.8773 - val_loss: 0.5079 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8371 - loss: 0.5747 - val_accuracy: 0.8874 - val_loss: 0.5112 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8410 - loss: 0.5626 - val_accuracy: 0.8787 - val_loss: 0.5068 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8386 - loss: 0.5651 - val_accuracy: 0.8776 - val_loss: 0.5033 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8395 - loss: 0.5686 - val_accuracy: 0.8753 - val_loss: 0.5190 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8311 - loss: 0.5879 - val_accuracy: 0.8941 - val_loss: 0.4818 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8446 - loss: 0.5697 - val_accuracy: 0.8886 - val_loss: 0.4917 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8468 - loss: 0.5590 - val_accuracy: 0.8892 - val_loss: 0.4810 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8445 - loss: 0.5636 - val_accuracy: 0.8944 - val_loss: 0.4700 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8511 - loss: 0.5466 - val_accuracy: 0.8959 - val_loss: 0.4715 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8498 - loss: 0.5487 - val_accuracy: 0.9005 - val_loss: 0.4709 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8529 - loss: 0.5468 - val_accuracy: 0.8932 - val_loss: 0.4674 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.8515 - loss: 0.5566 - val_accuracy: 0.8970 - val_loss: 0.4733 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.8536 - loss: 0.5464 - val_accuracy: 0.8988 - val_loss: 0.4611 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.8504 - loss: 0.5493 - val_accuracy: 0.9037 - val_loss: 0.4621 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.8521 - loss: 0.5439 - val_accuracy: 0.9072 - val_loss: 0.4594 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.8598 - loss: 0.5376 - val_accuracy: 0.9011 - val_loss: 0.4621 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8582 - loss: 0.5354 - val_accuracy: 0.9176 - val_loss: 0.4326 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.8640 - loss: 0.5219 - val_accuracy: 0.9017 - val_loss: 0.4486 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.8588 - loss: 0.5464 - val_accuracy: 0.9051 - val_loss: 0.4570 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.8555 - loss: 0.5417 - val_accuracy: 0.9051 - val_loss: 0.4541 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8659 - loss: 0.5131 - val_accuracy: 0.9179 - val_loss: 0.4139 - learning_rate: 1.2500e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8765 - loss: 0.4841 - val_accuracy: 0.9124 - val_loss: 0.4195 - learning_rate: 1.2500e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8797 - loss: 0.4847 - val_accuracy: 0.9188 - val_loss: 0.4089 - learning_rate: 1.2500e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8817 - loss: 0.4727 - val_accuracy: 0.9237 - val_loss: 0.3930 - learning_rate: 1.2500e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.8860 - loss: 0.4642 - val_accuracy: 0.9240 - val_loss: 0.4034 - learning_rate: 1.2500e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.8874 - loss: 0.4501 - val_accuracy: 0.9208 - val_loss: 0.4018 - learning_rate: 1.2500e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.8806 - loss: 0.4765 - val_accuracy: 0.9321 - val_loss: 0.3791 - learning_rate: 1.2500e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.8821 - loss: 0.4689 - val_accuracy: 0.9278 - val_loss: 0.3795 - learning_rate: 1.2500e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8885 - loss: 0.4378 - val_accuracy: 0.9318 - val_loss: 0.3765 - learning_rate: 1.2500e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8928 - loss: 0.4404 - val_accuracy: 0.9330 - val_loss: 0.3672 - learning_rate: 1.2500e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9000 - loss: 0.4267 - val_accuracy: 0.9307 - val_loss: 0.3676 - learning_rate: 1.2500e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.8912 - loss: 0.4429 - val_accuracy: 0.9283 - val_loss: 0.3757 - learning_rate: 1.2500e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.8940 - loss: 0.4343 - val_accuracy: 0.9399 - val_loss: 0.3631 - learning_rate: 1.2500e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8904 - loss: 0.4383 - val_accuracy: 0.9220 - val_loss: 0.3798 - learning_rate: 1.2500e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.8906 - loss: 0.4383 - val_accuracy: 0.9359 - val_loss: 0.3552 - learning_rate: 1.2500e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.8896 - loss: 0.4465 - val_accuracy: 0.9347 - val_loss: 0.3557 - learning_rate: 1.2500e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.8943 - loss: 0.4303 - val_accuracy: 0.9327 - val_loss: 0.3642 - learning_rate: 1.2500e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.8964 - loss: 0.4224 - val_accuracy: 0.9347 - val_loss: 0.3552 - learning_rate: 1.2500e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8933 - loss: 0.4226 - val_accuracy: 0.9402 - val_loss: 0.3417 - learning_rate: 6.2500e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.8964 - loss: 0.4178 - val_accuracy: 0.9385 - val_loss: 0.3414 - learning_rate: 6.2500e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9024 - loss: 0.4054 - val_accuracy: 0.9341 - val_loss: 0.3456 - learning_rate: 6.2500e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.9058 - loss: 0.3965 - val_accuracy: 0.9402 - val_loss: 0.3330 - learning_rate: 6.2500e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9041 - loss: 0.4014 - val_accuracy: 0.9437 - val_loss: 0.3255 - learning_rate: 6.2500e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9040 - loss: 0.4010 - val_accuracy: 0.9423 - val_loss: 0.3295 - learning_rate: 6.2500e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9080 - loss: 0.3882 - val_accuracy: 0.9382 - val_loss: 0.3303 - learning_rate: 6.2500e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9162 - loss: 0.3762 - val_accuracy: 0.9405 - val_loss: 0.3261 - learning_rate: 6.2500e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9066 - loss: 0.3933 - val_accuracy: 0.9373 - val_loss: 0.3294 - learning_rate: 3.1250e-05\n",
      "Epoch 94/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9138 - loss: 0.3776 - val_accuracy: 0.9382 - val_loss: 0.3286 - learning_rate: 3.1250e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9151 - loss: 0.3650 - val_accuracy: 0.9405 - val_loss: 0.3232 - learning_rate: 3.1250e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9134 - loss: 0.3680 - val_accuracy: 0.9443 - val_loss: 0.3174 - learning_rate: 3.1250e-05\n",
      "Epoch 97/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9185 - loss: 0.3626 - val_accuracy: 0.9428 - val_loss: 0.3204 - learning_rate: 3.1250e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9179 - loss: 0.3575 - val_accuracy: 0.9443 - val_loss: 0.3174 - learning_rate: 3.1250e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9146 - loss: 0.3627 - val_accuracy: 0.9449 - val_loss: 0.3154 - learning_rate: 3.1250e-05\n",
      "Epoch 100/100\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.9167 - loss: 0.3619 - val_accuracy: 0.9423 - val_loss: 0.3206 - learning_rate: 3.1250e-05\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
      "\n",
      "🧾 Fold 5 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.91      0.99      0.95       523\n",
      "     Jogging       0.95      0.88      0.91       565\n",
      "     Sitting       1.00      1.00      1.00       521\n",
      "    Standing       0.99      1.00      1.00       577\n",
      "    Upstairs       0.90      0.99      0.94       585\n",
      "     Walking       0.93      0.84      0.88       676\n",
      "\n",
      "    accuracy                           0.94      3447\n",
      "   macro avg       0.95      0.95      0.95      3447\n",
      "weighted avg       0.95      0.94      0.94      3447\n",
      "\n",
      "\n",
      "✅ Average Macro F1-Score across 5 folds: 0.9500 ± 0.0058\n"
     ]
    }
   ],
   "source": [
    "# === REPLACE your old training script with this one ===\n",
    "\n",
    "# Build CNN-LSTM with residual connections\n",
    "def build_cnn_lstm_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # CNN Block 1\n",
    "    x = Conv1D(64, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Residual Connection\n",
    "    conv1 = Conv1D(64, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    x = Add()([x, conv1])\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # CNN Block 2\n",
    "    x = Conv1D(128, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # LSTM Layer\n",
    "    x = LSTM(128, return_sequences=False, kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Dense Layers\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "f1_scores = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(X_augmented, y_augmented):\n",
    "    print(f\"\\n📚 Training Fold {fold}\")\n",
    "    X_train, X_val = X_augmented[train_idx], X_augmented[val_idx]\n",
    "    y_train, y_val = y_augmented[train_idx], y_augmented[val_idx]\n",
    "    \n",
    "    # Optional: light data augmentation on training data (e.g., jittering)\n",
    "    # X_train = add_jitter(X_train, sigma=0.02)\n",
    "\n",
    "    model = build_cnn_lstm_model(input_shape=(10, 3), num_classes=len(np.unique(y_augmented)))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        class_weight=class_weight_dict_aug,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    print(f\"\\n🧾 Fold {fold} Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred_classes, target_names=label_encoder.classes_))\n",
    "    \n",
    "    # Store macro F1-score\n",
    "    report = classification_report(y_val, y_pred_classes, output_dict=True)\n",
    "    f1_scores.append(report['macro avg']['f1-score'])\n",
    "    fold += 1\n",
    "\n",
    "# Final macro F1 score across folds\n",
    "print(f\"\\n✅ Average Macro F1-Score across {skf.n_splits} folds: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5d4bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ dropout_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ dropout_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_24          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │ dropout_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m3\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m1,024\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m20,544\u001b[0m │ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m41,088\u001b[0m │ dropout_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m131,584\u001b[0m │ dropout_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_24          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │        \u001b[38;5;34m774\u001b[0m │ dropout_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">636,628</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m636,628\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,038</span> (828.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m212,038\u001b[0m (828.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">424,078</span> (1.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m424,078\u001b[0m (1.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83d02b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model (architecture + weights + optimizer state)\n",
    "model.save('HAR.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03966da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 21 variables whereas the saved optimizer has 40 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "Accuracy: 0.9440753045404208\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.86      1.00      0.92       528\n",
      "     Jogging       0.97      0.93      0.95      1625\n",
      "     Sitting       1.00      1.00      1.00       306\n",
      "    Standing       0.98      1.00      0.99       246\n",
      "    Upstairs       0.87      0.99      0.93       632\n",
      "     Walking       0.96      0.91      0.94      2081\n",
      "\n",
      "    accuracy                           0.94      5418\n",
      "   macro avg       0.94      0.97      0.95      5418\n",
      "weighted avg       0.95      0.94      0.94      5418\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# === Load your original dataset (without augmentation) ===\n",
    "data = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\HAR-WISDM\\Data_WISDM\\WISDM_cleaned.csv\")\n",
    "\n",
    "# === Prepare X and y ===\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Label encoding for y\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape for CNN-LSTM input (assuming 10 time steps × 3 features)\n",
    "X_reshaped = X_scaled.reshape(-1, 10, 3)\n",
    "\n",
    "# === Load your saved model ===\n",
    "model = load_model(r'C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\HAR-WISDM\\HAR.keras')  # <-- replace with your saved model path\n",
    "\n",
    "# === Predict ===\n",
    "y_pred_probs = model.predict(X_reshaped)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# === Metrics ===\n",
    "print(\"Accuracy:\", accuracy_score(y_encoded, y_pred_classes))\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_encoded, y_pred_classes, target_names=label_encoder.classes_))\n",
    "\n",
    "# Optional: Confusion matrix visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_encoded, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
