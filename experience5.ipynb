{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f87fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“š Training Fold 1\n",
      "âœ… Augmented class Downstairs: original 422, +aug 2484\n",
      "âš ï¸ Skipping augmentation for class: Jogging\n",
      "âš ï¸ Skipping augmentation for class: Sitting\n",
      "âš ï¸ Skipping augmentation for class: Standing\n",
      "âœ… Augmented class Upstairs: original 506, +aug 2316\n",
      "âš ï¸ Skipping augmentation for class: Walking\n",
      "Epoch 1/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.2607 - loss: 3.4035 - val_accuracy: 0.3810 - val_loss: 1.8599 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3531 - loss: 1.6346 - val_accuracy: 0.3192 - val_loss: 1.6025 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3595 - loss: 1.3994 - val_accuracy: 0.3367 - val_loss: 1.5625 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3805 - loss: 1.3414 - val_accuracy: 0.4511 - val_loss: 1.4071 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3845 - loss: 1.3091 - val_accuracy: 0.4982 - val_loss: 1.3744 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3951 - loss: 1.2800 - val_accuracy: 0.4336 - val_loss: 1.4449 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3784 - loss: 1.3179 - val_accuracy: 0.3967 - val_loss: 1.4581 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4157 - loss: 1.2931 - val_accuracy: 0.5258 - val_loss: 1.3339 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.3887 - loss: 1.2729 - val_accuracy: 0.5443 - val_loss: 1.3172 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4152 - loss: 1.2746 - val_accuracy: 0.4437 - val_loss: 1.4608 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3997 - loss: 1.2780 - val_accuracy: 0.5341 - val_loss: 1.3354 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4308 - loss: 1.2159 - val_accuracy: 0.5655 - val_loss: 1.3176 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4248 - loss: 1.2377 - val_accuracy: 0.5747 - val_loss: 1.2774 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4447 - loss: 1.1798 - val_accuracy: 0.6116 - val_loss: 1.2093 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4336 - loss: 1.1772 - val_accuracy: 0.5941 - val_loss: 1.2402 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4451 - loss: 1.1747 - val_accuracy: 0.5969 - val_loss: 1.2352 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4491 - loss: 1.0970 - val_accuracy: 0.5470 - val_loss: 1.2598 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4613 - loss: 1.0779 - val_accuracy: 0.6153 - val_loss: 1.1714 - learning_rate: 2.5000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4658 - loss: 1.0629 - val_accuracy: 0.5609 - val_loss: 1.2105 - learning_rate: 2.5000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4738 - loss: 1.0543 - val_accuracy: 0.5683 - val_loss: 1.1974 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4776 - loss: 1.0081 - val_accuracy: 0.6116 - val_loss: 1.1604 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4717 - loss: 1.0345 - val_accuracy: 0.5932 - val_loss: 1.1592 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4804 - loss: 1.0090 - val_accuracy: 0.6144 - val_loss: 1.1348 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4844 - loss: 1.0008 - val_accuracy: 0.6273 - val_loss: 1.1069 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4894 - loss: 0.9820 - val_accuracy: 0.6153 - val_loss: 1.1389 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4851 - loss: 0.9868 - val_accuracy: 0.6310 - val_loss: 1.1112 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5060 - loss: 0.9620 - val_accuracy: 0.6125 - val_loss: 1.1514 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5027 - loss: 0.9539 - val_accuracy: 0.6227 - val_loss: 1.1041 - learning_rate: 1.2500e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5007 - loss: 0.9481 - val_accuracy: 0.6227 - val_loss: 1.0998 - learning_rate: 1.2500e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4974 - loss: 0.9443 - val_accuracy: 0.6190 - val_loss: 1.1017 - learning_rate: 1.2500e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5045 - loss: 0.9159 - val_accuracy: 0.6273 - val_loss: 1.0909 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4988 - loss: 0.9206 - val_accuracy: 0.6292 - val_loss: 1.0741 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5060 - loss: 0.9264 - val_accuracy: 0.6282 - val_loss: 1.0810 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5131 - loss: 0.9133 - val_accuracy: 0.6089 - val_loss: 1.1305 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5143 - loss: 0.9220 - val_accuracy: 0.6301 - val_loss: 1.0778 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5270 - loss: 0.8936 - val_accuracy: 0.6319 - val_loss: 1.0728 - learning_rate: 6.2500e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5225 - loss: 0.8731 - val_accuracy: 0.6375 - val_loss: 1.0714 - learning_rate: 6.2500e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5289 - loss: 0.8828 - val_accuracy: 0.6292 - val_loss: 1.0818 - learning_rate: 6.2500e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5227 - loss: 0.8884 - val_accuracy: 0.6292 - val_loss: 1.0657 - learning_rate: 6.2500e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5192 - loss: 0.8662 - val_accuracy: 0.6328 - val_loss: 1.0700 - learning_rate: 6.2500e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5274 - loss: 0.8534 - val_accuracy: 0.6319 - val_loss: 1.0696 - learning_rate: 6.2500e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5382 - loss: 0.8574 - val_accuracy: 0.6301 - val_loss: 1.0667 - learning_rate: 6.2500e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5243 - loss: 0.8620 - val_accuracy: 0.6347 - val_loss: 1.0628 - learning_rate: 3.1250e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5381 - loss: 0.8682 - val_accuracy: 0.6467 - val_loss: 1.0469 - learning_rate: 3.1250e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5217 - loss: 0.8440 - val_accuracy: 0.6347 - val_loss: 1.0522 - learning_rate: 3.1250e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5242 - loss: 0.8479 - val_accuracy: 0.6458 - val_loss: 1.0456 - learning_rate: 3.1250e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5227 - loss: 0.8419 - val_accuracy: 0.6485 - val_loss: 1.0518 - learning_rate: 3.1250e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5282 - loss: 0.8349 - val_accuracy: 0.6476 - val_loss: 1.0461 - learning_rate: 3.1250e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5341 - loss: 0.8382 - val_accuracy: 0.6430 - val_loss: 1.0484 - learning_rate: 3.1250e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5329 - loss: 0.8379 - val_accuracy: 0.6421 - val_loss: 1.0489 - learning_rate: 1.5625e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5321 - loss: 0.8394 - val_accuracy: 0.6504 - val_loss: 1.0410 - learning_rate: 1.5625e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5291 - loss: 0.8269 - val_accuracy: 0.6476 - val_loss: 1.0460 - learning_rate: 1.5625e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5452 - loss: 0.8122 - val_accuracy: 0.6476 - val_loss: 1.0377 - learning_rate: 1.5625e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5334 - loss: 0.8293 - val_accuracy: 0.6513 - val_loss: 1.0428 - learning_rate: 1.5625e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5290 - loss: 0.8319 - val_accuracy: 0.6458 - val_loss: 1.0426 - learning_rate: 1.5625e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5405 - loss: 0.8206 - val_accuracy: 0.6522 - val_loss: 1.0402 - learning_rate: 1.5625e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5318 - loss: 0.8318 - val_accuracy: 0.6485 - val_loss: 1.0415 - learning_rate: 7.8125e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5329 - loss: 0.8231 - val_accuracy: 0.6494 - val_loss: 1.0412 - learning_rate: 7.8125e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5317 - loss: 0.8242 - val_accuracy: 0.6448 - val_loss: 1.0432 - learning_rate: 7.8125e-06\n",
      "Epoch 60/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5451 - loss: 0.8241 - val_accuracy: 0.6504 - val_loss: 1.0450 - learning_rate: 3.9063e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5333 - loss: 0.8157 - val_accuracy: 0.6467 - val_loss: 1.0422 - learning_rate: 3.9063e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5436 - loss: 0.8170 - val_accuracy: 0.6504 - val_loss: 1.0386 - learning_rate: 3.9063e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5215 - loss: 0.8298 - val_accuracy: 0.6504 - val_loss: 1.0406 - learning_rate: 1.9531e-06\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\n",
      "ðŸ§¾ Fold 1 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.29      0.42      0.34       106\n",
      "     Jogging       0.80      0.74      0.77       325\n",
      "     Sitting       0.90      0.85      0.87        61\n",
      "    Standing       0.75      0.78      0.76        49\n",
      "    Upstairs       0.19      0.07      0.10       126\n",
      "     Walking       0.68      0.76      0.72       417\n",
      "\n",
      "    accuracy                           0.65      1084\n",
      "   macro avg       0.60      0.60      0.59      1084\n",
      "weighted avg       0.63      0.65      0.63      1084\n",
      "\n",
      "\n",
      "ðŸ“š Training Fold 2\n",
      "âœ… Augmented class Downstairs: original 423, +aug 2484\n",
      "âš ï¸ Skipping augmentation for class: Jogging\n",
      "âš ï¸ Skipping augmentation for class: Sitting\n",
      "âš ï¸ Skipping augmentation for class: Standing\n",
      "âœ… Augmented class Upstairs: original 505, +aug 2320\n",
      "âš ï¸ Skipping augmentation for class: Walking\n",
      "Epoch 1/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.3164 - loss: 3.4126 - val_accuracy: 0.4336 - val_loss: 1.9008 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3439 - loss: 1.7078 - val_accuracy: 0.3496 - val_loss: 1.6540 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.3664 - loss: 1.4614 - val_accuracy: 0.4696 - val_loss: 1.4428 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3918 - loss: 1.3601 - val_accuracy: 0.4373 - val_loss: 1.4768 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3956 - loss: 1.3350 - val_accuracy: 0.5489 - val_loss: 1.3214 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3911 - loss: 1.3297 - val_accuracy: 0.4788 - val_loss: 1.3844 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4185 - loss: 1.2925 - val_accuracy: 0.4889 - val_loss: 1.3770 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4176 - loss: 1.2635 - val_accuracy: 0.6024 - val_loss: 1.2736 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3983 - loss: 1.3076 - val_accuracy: 0.4659 - val_loss: 1.3989 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4129 - loss: 1.2601 - val_accuracy: 0.4825 - val_loss: 1.3837 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4301 - loss: 1.2246 - val_accuracy: 0.4548 - val_loss: 1.4761 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4322 - loss: 1.2124 - val_accuracy: 0.5138 - val_loss: 1.3390 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m 80/286\u001b[0m \u001b[32mâ”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4784 - loss: 1.1128"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 151\u001b[0m\n\u001b[0;32m    148\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    149\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m--> 151\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_balanced\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    159\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m    162\u001b[0m y_pred_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\MSI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization, Add, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "from collections import Counter\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# === Attention Layer ===\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\", trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        e = K.squeeze(e, axis=-1)\n",
    "        alpha = K.softmax(e)\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        context = K.sum(alpha * x, axis=1)\n",
    "        return context\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n",
    "# === Augmentation Functions ===\n",
    "def time_warp(X, sigma=0.2):\n",
    "    orig_steps = np.arange(X.shape[1])\n",
    "    X_warped = np.zeros_like(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        random_warp = np.random.normal(loc=1.0, scale=sigma, size=(X.shape[1],))\n",
    "        warped_steps = np.cumsum(random_warp)\n",
    "        warped_steps = (warped_steps - warped_steps.min()) / (warped_steps.max() - warped_steps.min()) * (X.shape[1] - 1)\n",
    "        cs = CubicSpline(orig_steps, X[i])\n",
    "        X_warped[i] = cs(warped_steps)\n",
    "    return X_warped\n",
    "\n",
    "def add_jitter(X, sigma=0.05):\n",
    "    return X + np.random.normal(loc=0.0, scale=sigma, size=X.shape)\n",
    "\n",
    "# === Load and preprocess data ===\n",
    "data = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\HAR-WISDM\\Data_WISDM\\WISDM_cleaned.csv\")\n",
    "X = data.drop('class', axis=1).values\n",
    "y = data['class'].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_reshaped = X_scaled.reshape(-1, 10, 3)\n",
    "y_reshaped = y_encoded.reshape(-1)\n",
    "\n",
    "# === Model Builder ===\n",
    "def build_cnn_lstm_attention_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(64, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    conv1 = Conv1D(64, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    x = Add()([x, conv1])\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = LSTM(64, return_sequences=True, kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Attention()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Cross-validation and Augmentation ===\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "f1_scores = []\n",
    "\n",
    "excluded_classes = ['Walking', 'Jogging','Sitting', 'Standing']\n",
    "excluded_class_ids = label_encoder.transform(excluded_classes)\n",
    "\n",
    "for train_idx, val_idx in skf.split(X_reshaped, y_reshaped):\n",
    "    print(f\"\\nðŸ“š Training Fold {fold}\")\n",
    "    X_train, X_val = X_reshaped[train_idx], X_reshaped[val_idx]\n",
    "    y_train, y_val = y_reshaped[train_idx], y_reshaped[val_idx]\n",
    "\n",
    "    X_aug, y_aug = [], []\n",
    "    counter = Counter(y_train)\n",
    "    max_count = max(counter.values())\n",
    "\n",
    "    for cls in np.unique(y_train):\n",
    "        X_cls = X_train[y_train == cls]\n",
    "        y_cls = y_train[y_train == cls]\n",
    "\n",
    "        if cls in excluded_class_ids:\n",
    "            print(f\"âš ï¸ Skipping augmentation for class: {label_encoder.inverse_transform([cls])[0]}\")\n",
    "            X_aug.append(X_cls)\n",
    "            y_aug.append(y_cls)\n",
    "            continue\n",
    "\n",
    "        n_to_add = max_count - len(X_cls)\n",
    "        reps = n_to_add // len(X_cls) + 1\n",
    "\n",
    "        X_jittered = np.concatenate([add_jitter(X_cls) for _ in range(reps)], axis=0)[:n_to_add]\n",
    "        X_timewarped = np.concatenate([time_warp(X_cls) for _ in range(reps)], axis=0)[:n_to_add]\n",
    "        X_augmented = np.concatenate([X_jittered, X_timewarped], axis=0)\n",
    "        y_augmented = np.full(len(X_augmented), cls)\n",
    "\n",
    "        print(f\"âœ… Augmented class {label_encoder.inverse_transform([cls])[0]}: original {len(X_cls)}, +aug {len(X_augmented)}\")\n",
    "\n",
    "        X_aug.append(np.concatenate([X_cls, X_augmented], axis=0))\n",
    "        y_aug.append(np.concatenate([y_cls, y_augmented], axis=0))\n",
    "\n",
    "    X_train_balanced = np.concatenate(X_aug, axis=0)\n",
    "    y_train_balanced = np.concatenate(y_aug, axis=0)\n",
    "\n",
    "    indices = np.arange(len(X_train_balanced))\n",
    "    np.random.shuffle(indices)\n",
    "    X_train_balanced = X_train_balanced[indices]\n",
    "    y_train_balanced = y_train_balanced[indices]\n",
    "\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_balanced), y=y_train_balanced)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    model = build_cnn_lstm_attention_model(input_shape=(10, 3), num_classes=len(np.unique(y_reshaped)))\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_balanced, y_train_balanced,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        class_weight=class_weight_dict,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print(f\"\\nðŸ§¾ Fold {fold} Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred_classes, target_names=label_encoder.classes_))\n",
    "\n",
    "    report = classification_report(y_val, y_pred_classes, output_dict=True)\n",
    "    f1_scores.append(report['macro avg']['f1-score'])\n",
    "    fold += 1\n",
    "\n",
    "print(f\"\\nâœ… Average Macro F1-Score across {skf.n_splits} folds: {np.mean(f1_scores):.4f} Â± {np.std(f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ecfab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“š Training Fold 1\n",
      "âœ… Augmented class Downstairs: original 422, +aug 2484\n",
      "âš ï¸ Skipping augmentation for class: Jogging\n",
      "âš ï¸ Skipping augmentation for class: Sitting\n",
      "âš ï¸ Skipping augmentation for class: Standing\n",
      "âœ… Augmented class Upstairs: original 506, +aug 2316\n",
      "âš ï¸ Skipping augmentation for class: Walking\n",
      "Epoch 1/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.2603 - loss: 3.4758 - val_accuracy: 0.2177 - val_loss: 2.0770 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.3588 - loss: 1.6669 - val_accuracy: 0.4899 - val_loss: 1.5237 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.3595 - loss: 1.4349 - val_accuracy: 0.4096 - val_loss: 1.4728 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.3784 - loss: 1.4054 - val_accuracy: 0.4041 - val_loss: 1.4698 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - accuracy: 0.3904 - loss: 1.3217 - val_accuracy: 0.4659 - val_loss: 1.4509 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.3971 - loss: 1.3078 - val_accuracy: 0.4917 - val_loss: 1.3694 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 68ms/step - accuracy: 0.4045 - loss: 1.2819 - val_accuracy: 0.4649 - val_loss: 1.4395 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - accuracy: 0.4119 - loss: 1.3157 - val_accuracy: 0.4668 - val_loss: 1.4484 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.4170 - loss: 1.2919 - val_accuracy: 0.5775 - val_loss: 1.3004 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - accuracy: 0.4212 - loss: 1.2752 - val_accuracy: 0.5092 - val_loss: 1.3688 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.4260 - loss: 1.2703 - val_accuracy: 0.5876 - val_loss: 1.2718 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - accuracy: 0.4253 - loss: 1.2345 - val_accuracy: 0.5240 - val_loss: 1.3419 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.4368 - loss: 1.2458 - val_accuracy: 0.6098 - val_loss: 1.2524 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.4482 - loss: 1.2204 - val_accuracy: 0.5600 - val_loss: 1.2980 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4267 - loss: 1.2342 - val_accuracy: 0.5821 - val_loss: 1.2516 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4409 - loss: 1.2460 - val_accuracy: 0.5627 - val_loss: 1.2975 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4325 - loss: 1.2540 - val_accuracy: 0.5950 - val_loss: 1.2743 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - accuracy: 0.4490 - loss: 1.2166 - val_accuracy: 0.5470 - val_loss: 1.2974 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 44ms/step - accuracy: 0.4610 - loss: 1.1414 - val_accuracy: 0.6052 - val_loss: 1.2124 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.4567 - loss: 1.1265 - val_accuracy: 0.6033 - val_loss: 1.1643 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4713 - loss: 1.1001 - val_accuracy: 0.5923 - val_loss: 1.1997 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4684 - loss: 1.0987 - val_accuracy: 0.6162 - val_loss: 1.1662 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4611 - loss: 1.0941 - val_accuracy: 0.6024 - val_loss: 1.1674 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4805 - loss: 1.0354 - val_accuracy: 0.6328 - val_loss: 1.1406 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4781 - loss: 1.0194 - val_accuracy: 0.6218 - val_loss: 1.1270 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4936 - loss: 1.0057 - val_accuracy: 0.5886 - val_loss: 1.1576 - learning_rate: 2.5000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4966 - loss: 1.0037 - val_accuracy: 0.6328 - val_loss: 1.0953 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4837 - loss: 0.9813 - val_accuracy: 0.6236 - val_loss: 1.1007 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5022 - loss: 0.9528 - val_accuracy: 0.6006 - val_loss: 1.1598 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4918 - loss: 0.9674 - val_accuracy: 0.6135 - val_loss: 1.1246 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5104 - loss: 0.9617 - val_accuracy: 0.6375 - val_loss: 1.0798 - learning_rate: 1.2500e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5110 - loss: 0.9189 - val_accuracy: 0.6310 - val_loss: 1.0702 - learning_rate: 1.2500e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5130 - loss: 0.9183 - val_accuracy: 0.6356 - val_loss: 1.0875 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5244 - loss: 0.8979 - val_accuracy: 0.6458 - val_loss: 1.0561 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5201 - loss: 0.9140 - val_accuracy: 0.6375 - val_loss: 1.0539 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5235 - loss: 0.8958 - val_accuracy: 0.6439 - val_loss: 1.0541 - learning_rate: 1.2500e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5030 - loss: 0.8971 - val_accuracy: 0.6384 - val_loss: 1.0521 - learning_rate: 1.2500e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.5216 - loss: 0.8842 - val_accuracy: 0.6485 - val_loss: 1.0538 - learning_rate: 1.2500e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 47ms/step - accuracy: 0.5260 - loss: 0.8772 - val_accuracy: 0.6494 - val_loss: 1.0503 - learning_rate: 1.2500e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.5120 - loss: 0.8711 - val_accuracy: 0.6458 - val_loss: 1.0480 - learning_rate: 1.2500e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 36ms/step - accuracy: 0.5187 - loss: 0.8817 - val_accuracy: 0.6476 - val_loss: 1.0436 - learning_rate: 1.2500e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.5341 - loss: 0.8554 - val_accuracy: 0.5996 - val_loss: 1.0896 - learning_rate: 1.2500e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - accuracy: 0.5316 - loss: 0.8822 - val_accuracy: 0.6531 - val_loss: 1.0401 - learning_rate: 1.2500e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.5437 - loss: 0.8622 - val_accuracy: 0.6430 - val_loss: 1.0512 - learning_rate: 1.2500e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.5377 - loss: 0.8361 - val_accuracy: 0.6421 - val_loss: 1.0317 - learning_rate: 1.2500e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.5391 - loss: 0.8407 - val_accuracy: 0.6282 - val_loss: 1.0620 - learning_rate: 1.2500e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.5412 - loss: 0.8632 - val_accuracy: 0.6531 - val_loss: 1.0397 - learning_rate: 1.2500e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5279 - loss: 0.8470 - val_accuracy: 0.6319 - val_loss: 1.0450 - learning_rate: 1.2500e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.5433 - loss: 0.8332 - val_accuracy: 0.6494 - val_loss: 1.0335 - learning_rate: 6.2500e-05\n",
      "Epoch 50/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.5400 - loss: 0.8554 - val_accuracy: 0.6448 - val_loss: 1.0374 - learning_rate: 6.2500e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5405 - loss: 0.8230 - val_accuracy: 0.6439 - val_loss: 1.0375 - learning_rate: 6.2500e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5488 - loss: 0.8119 - val_accuracy: 0.6458 - val_loss: 1.0271 - learning_rate: 3.1250e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5406 - loss: 0.8155 - val_accuracy: 0.6504 - val_loss: 1.0296 - learning_rate: 3.1250e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5522 - loss: 0.8106 - val_accuracy: 0.6485 - val_loss: 1.0279 - learning_rate: 3.1250e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.5475 - loss: 0.8004 - val_accuracy: 0.6485 - val_loss: 1.0235 - learning_rate: 3.1250e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5479 - loss: 0.8176 - val_accuracy: 0.6458 - val_loss: 1.0283 - learning_rate: 3.1250e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5468 - loss: 0.8099 - val_accuracy: 0.6467 - val_loss: 1.0273 - learning_rate: 3.1250e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5614 - loss: 0.8044 - val_accuracy: 0.6439 - val_loss: 1.0278 - learning_rate: 3.1250e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.5590 - loss: 0.8114 - val_accuracy: 0.6430 - val_loss: 1.0345 - learning_rate: 1.5625e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 47ms/step - accuracy: 0.5582 - loss: 0.8033 - val_accuracy: 0.6402 - val_loss: 1.0324 - learning_rate: 1.5625e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - accuracy: 0.5603 - loss: 0.8177 - val_accuracy: 0.6467 - val_loss: 1.0251 - learning_rate: 1.5625e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.5576 - loss: 0.8119 - val_accuracy: 0.6504 - val_loss: 1.0235 - learning_rate: 7.8125e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.5543 - loss: 0.7960 - val_accuracy: 0.6494 - val_loss: 1.0262 - learning_rate: 7.8125e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.5571 - loss: 0.7883 - val_accuracy: 0.6476 - val_loss: 1.0265 - learning_rate: 7.8125e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m286/286\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.5633 - loss: 0.7885 - val_accuracy: 0.6504 - val_loss: 1.0278 - learning_rate: 3.9063e-06\n",
      "\u001b[1m34/34\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step\n",
      "\n",
      "ðŸ§¾ Fold 1 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Downstairs       0.30      0.42      0.35       106\n",
      "     Jogging       0.78      0.74      0.76       325\n",
      "     Sitting       0.89      0.95      0.92        61\n",
      "    Standing       0.80      0.73      0.77        49\n",
      "    Upstairs       0.20      0.10      0.13       126\n",
      "     Walking       0.68      0.75      0.71       417\n",
      "\n",
      "    accuracy                           0.65      1084\n",
      "   macro avg       0.61      0.62      0.61      1084\n",
      "weighted avg       0.63      0.65      0.64      1084\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Analysis for class 'Downstairs':\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 190\u001b[0m\n\u001b[0;32m    187\u001b[0m precision, recall, f1, support \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m    188\u001b[0m     y_val, y_pred_classes, labels\u001b[38;5;241m=\u001b[39m[cls_id], average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ” Analysis for class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Recall:    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  F1-score:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization, Add, Layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "from collections import Counter\n",
    "from scipy.interpolate import CubicSpline\n",
    "import shap  # For explainability\n",
    "\n",
    "# === Attention Layer ===\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\", trainable=True)\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        e = K.squeeze(e, axis=-1)\n",
    "        alpha = K.softmax(e)\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        context = K.sum(alpha * x, axis=1)\n",
    "        return context\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "\n",
    "# === Augmentation Functions ===\n",
    "def time_warp(X, sigma=0.2):\n",
    "    orig_steps = np.arange(X.shape[1])\n",
    "    X_warped = np.zeros_like(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        random_warp = np.random.normal(loc=1.0, scale=sigma, size=(X.shape[1],))\n",
    "        warped_steps = np.cumsum(random_warp)\n",
    "        warped_steps = (warped_steps - warped_steps.min()) / (warped_steps.max() - warped_steps.min()) * (X.shape[1] - 1)\n",
    "        cs = CubicSpline(orig_steps, X[i])\n",
    "        X_warped[i] = cs(warped_steps)\n",
    "    return X_warped\n",
    "\n",
    "def add_jitter(X, sigma=0.05):\n",
    "    return X + np.random.normal(loc=0.0, scale=sigma, size=X.shape)\n",
    "\n",
    "# === Load and preprocess data ===\n",
    "data = pd.read_csv(r\"C:\\Users\\MSI\\Desktop\\Mitacs Project\\Human Activity Recognition\\HAR-WISDM\\Data_WISDM\\WISDM_cleaned.csv\")\n",
    "X = data.drop('class', axis=1).values\n",
    "y = data['class'].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_reshaped = X_scaled.reshape(-1, 10, 3)\n",
    "y_reshaped = y_encoded.reshape(-1)\n",
    "\n",
    "# === Model Builder ===\n",
    "def build_cnn_lstm_attention_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(64, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    conv1 = Conv1D(64, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    x = Add()([x, conv1])\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv1D(64, kernel_size=5, padding='same', activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = LSTM(64, return_sequences=True, kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Attention()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === Cross-validation and Augmentation ===\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "f1_scores = []\n",
    "\n",
    "excluded_classes = ['Walking', 'Jogging','Sitting', 'Standing']\n",
    "excluded_class_ids = label_encoder.transform(excluded_classes)\n",
    "\n",
    "for train_idx, val_idx in skf.split(X_reshaped, y_reshaped):\n",
    "    print(f\"\\nðŸ“š Training Fold {fold}\")\n",
    "    X_train, X_val = X_reshaped[train_idx], X_reshaped[val_idx]\n",
    "    y_train, y_val = y_reshaped[train_idx], y_reshaped[val_idx]\n",
    "\n",
    "    # Augmentation block\n",
    "    X_aug, y_aug = [], []\n",
    "    counter = Counter(y_train)\n",
    "    max_count = max(counter.values())\n",
    "\n",
    "    for cls in np.unique(y_train):\n",
    "        X_cls = X_train[y_train == cls]\n",
    "        y_cls = y_train[y_train == cls]\n",
    "\n",
    "        if cls in excluded_class_ids:\n",
    "            print(f\"âš ï¸ Skipping augmentation for class: {label_encoder.inverse_transform([cls])[0]}\")\n",
    "            X_aug.append(X_cls)\n",
    "            y_aug.append(y_cls)\n",
    "            continue\n",
    "\n",
    "        n_to_add = max_count - len(X_cls)\n",
    "        reps = n_to_add // len(X_cls) + 1\n",
    "\n",
    "        X_jittered = np.concatenate([add_jitter(X_cls) for _ in range(reps)], axis=0)[:n_to_add]\n",
    "        X_timewarped = np.concatenate([time_warp(X_cls) for _ in range(reps)], axis=0)[:n_to_add]\n",
    "        X_augmented = np.concatenate([X_jittered, X_timewarped], axis=0)\n",
    "        y_augmented = np.full(len(X_augmented), cls)\n",
    "\n",
    "        print(f\"âœ… Augmented class {label_encoder.inverse_transform([cls])[0]}: original {len(X_cls)}, +aug {len(X_augmented)}\")\n",
    "\n",
    "        X_aug.append(np.concatenate([X_cls, X_augmented], axis=0))\n",
    "        y_aug.append(np.concatenate([y_cls, y_augmented], axis=0))\n",
    "\n",
    "    X_train_balanced = np.concatenate(X_aug, axis=0)\n",
    "    y_train_balanced = np.concatenate(y_aug, axis=0)\n",
    "\n",
    "    indices = np.arange(len(X_train_balanced))\n",
    "    np.random.shuffle(indices)\n",
    "    X_train_balanced = X_train_balanced[indices]\n",
    "    y_train_balanced = y_train_balanced[indices]\n",
    "\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train_balanced), y=y_train_balanced)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    model = build_cnn_lstm_attention_model(input_shape=(10, 3), num_classes=len(np.unique(y_reshaped)))\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_balanced, y_train_balanced,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        class_weight=class_weight_dict,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print(f\"\\nðŸ§¾ Fold {fold} Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred_classes, target_names=label_encoder.classes_))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_val, y_pred_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title(f\"Confusion Matrix - Fold {fold}\")\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "    # Detailed analysis for \"Downstairs\" and \"Upstairs\"\n",
    "    for cls_name in ['Downstairs', 'Upstairs']:\n",
    "        if cls_name in label_encoder.classes_:\n",
    "            cls_id = np.where(label_encoder.classes_ == cls_name)[0][0]\n",
    "            precision, recall, f1, support = precision_recall_fscore_support(\n",
    "                y_val, y_pred_classes, labels=[cls_id], average=None, zero_division=0)\n",
    "            print(f\"ðŸ” Analysis for class '{cls_name}':\")\n",
    "            print(f\"  Precision: {precision:.3f}\")\n",
    "            print(f\"  Recall:    {recall:.3f}\")\n",
    "            print(f\"  F1-score:  {f1:.3f}\")\n",
    "            print(f\"  Support:   {support}\")\n",
    "            print(f\"  Confusion matrix row (true {cls_name}): {cm[cls_id]}\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# === SHAP Explainability on last fold model ===\n",
    "print(\"\\nðŸ”Ž Running SHAP explainability on last fold model\")\n",
    "\n",
    "# Prepare a background dataset for SHAP (sample from training data)\n",
    "background = X_train_balanced[np.random.choice(X_train_balanced.shape[0], 100, replace=False)]\n",
    "\n",
    "# Create SHAP DeepExplainer (works with TF Keras)\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "\n",
    "# Take a sample of validation data for explanation\n",
    "X_val_sample = X_val[:100]\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer.shap_values(X_val_sample)\n",
    "\n",
    "# Plot SHAP summary plot for each class\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"\\nSHAP summary for class: {class_name}\")\n",
    "    shap.summary_plot(shap_values[i], X_val_sample, feature_names=[f\"t{t}_axis{a}\" for t in range(10) for a in ['X', 'Y', 'Z']])\n",
    "\n",
    "print(\"\\nâœ… Model training, evaluation, and explainability complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
